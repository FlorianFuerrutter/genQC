{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8980c24-d62e-462b-ba89-3195cfdcc374",
   "metadata": {},
   "source": [
    "# Tensor tokenizer\n",
    "\n",
    ">  Class to further tokenize tensor representations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8832bdd-f61c-44e1-8619-a9cb352ba768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T11:14:43.694724Z",
     "iopub.status.busy": "2025-06-01T11:14:43.694724Z",
     "iopub.status.idle": "2025-06-01T11:14:43.698114Z",
     "shell.execute_reply": "2025-06-01T11:14:43.697577Z",
     "shell.execute_reply.started": "2025-06-01T11:14:43.694724Z"
    }
   },
   "outputs": [],
   "source": [
    "#| default_exp platform.tokenizer.tensor_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06272f6f-b4e3-4504-a90a-feebbf6ad821",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T11:14:43.699102Z",
     "iopub.status.busy": "2025-06-01T11:14:43.698114Z",
     "iopub.status.idle": "2025-06-01T11:14:45.687430Z",
     "shell.execute_reply": "2025-06-01T11:14:45.687430Z",
     "shell.execute_reply.started": "2025-06-01T11:14:43.699102Z"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "from genQC.imports import *\n",
    "from genQC.platform.tokenizer.base_tokenizer import BaseTokenizer, Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6727ed63-a766-4893-8642-0d0e141c6cff",
   "metadata": {},
   "source": [
    "## GatePairTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a4b051b-eba3-4b3a-9bec-c5c44655bf26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T11:14:45.688440Z",
     "iopub.status.busy": "2025-06-01T11:14:45.688440Z",
     "iopub.status.idle": "2025-06-01T11:14:45.763076Z",
     "shell.execute_reply": "2025-06-01T11:14:45.763076Z",
     "shell.execute_reply.started": "2025-06-01T11:14:45.688440Z"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "class GatePairTokenizer(BaseTokenizer):\n",
    "\n",
    "    def __init__(self, unique_class_values, zero_token, padding_token, device):\n",
    "        super().__init__({})\n",
    "        \n",
    "        self.padding_token    = padding_token\n",
    "        self.not_gates_tokens = torch.tensor([zero_token, padding_token]).to(device)\n",
    "\n",
    "        self.current_tokens = torch.tensor(unique_class_values, device=device)\n",
    "        self._current_depth = 0\n",
    "        \n",
    "        self.token_lookup = {}      #reduced forms, used for gadget extraction\n",
    "        self.token_lookup_raw = {}  #the raw form, used for encoding\n",
    "        \n",
    "        self.token_depth  = {tok:0 for tok in self.current_tokens.cpu().tolist()}\n",
    "        self.token_cnts   = {}\n",
    "    \n",
    "    def learn(self, tensors, max_depth, max_iters):\n",
    "        # loop over get bets and then replace\n",
    "        \n",
    "        current_tensor = tensors\n",
    "        self._current_depth = 0\n",
    "        \n",
    "        for i in tqdm(range(max_iters), total=max_iters):\n",
    "        \n",
    "            overlap_pairs          = self.extract_new_gate_overlap_pairs(current_tensor)\n",
    "            overlap_pairs_std_form = self.standardize_overlap_pairs(overlap_pairs)\n",
    "\n",
    "            top_pairs, topv = self.get_topk_pairs(overlap_pairs_std_form, k=1)\n",
    "            top_pair = top_pairs[0]\n",
    "       \n",
    "            if top_pair.abs().sum() < 1:\n",
    "                print(\"break: top_pair.abs().sum() < 1\")\n",
    "                break\n",
    "\n",
    "            if topv < 2:\n",
    "                print(\"break: no more pair with cnt > 1\")\n",
    "                break\n",
    "            \n",
    "            current_tensor = self.learn_step(current_tensor, top_pair, topv=topv)\n",
    "\n",
    "            current_max_depth = max(self.token_depth.values())\n",
    "            if current_max_depth > max_depth:\n",
    "                print(f\"break: max_depth {max_depth} reached\")\n",
    "                break\n",
    "            \n",
    "        print(\"break: max_iters reached\")\n",
    "        return current_tensor\n",
    "\n",
    "    def to(self, device):\n",
    "        self.not_gates_tokens = self.not_gates_tokens.to(device) \n",
    "        self.current_tokens   = self.current_tokens.to(device) \n",
    "        \n",
    "        for k, v in self.token_lookup.items():\n",
    "            self.token_lookup[k] = self.token_lookup[k].to(device) \n",
    "            \n",
    "        for k, v in self.token_lookup_raw.items():\n",
    "            self.token_lookup_raw[k] = self.token_lookup_raw[k].to(device) \n",
    "        \n",
    "        return self\n",
    "\n",
    "    def tokenize(self, tensors):\n",
    "        \"\"\"Identical to `GatePairTokenizer.encode`.\"\"\"\n",
    "        return self.encode(tensors=tensors)\n",
    "    \n",
    "    #---------------------------------------\n",
    "    # Replace pairs with new tokens\n",
    "\n",
    "    def learn_step(self, current_tensor, top_pair, new_tokens: Optional[torch.Tensor] = None, topv: Optional[torch.Tensor] = None):\n",
    "\n",
    "        top_pair_reduced = top_pair[top_pair.abs().sum(-1)>0].unique_consecutive(dim=0)\n",
    "\n",
    "        if not_exists(new_tokens):\n",
    "            new_tokens = self.current_tokens.max() + 1 + torch.arange(top_pair_reduced.shape[0], device=current_tensor.device)\n",
    "            self.current_tokens = torch.cat([self.current_tokens, new_tokens])\n",
    "\n",
    "            key = tuple(new_tokens.cpu().tolist())\n",
    "            self.token_lookup[key]     = top_pair_reduced  #top_pair[top_pair.sum(-1)>0]\n",
    "            self.token_lookup_raw[key] = top_pair\n",
    "            self.token_cnts[key]   = topv\n",
    "            \n",
    "            _current_depth = max(self.token_depth[k] for k in top_pair_reduced.flatten().cpu().tolist()) + 1\n",
    "            \n",
    "            for tok in new_tokens.cpu().tolist():\n",
    "                self.token_depth[tok] = _current_depth\n",
    "\n",
    "            if _current_depth > self._current_depth:\n",
    "                self._current_depth = _current_depth\n",
    "                print(f\"New depth reached {self._current_depth}\")\n",
    "        else:\n",
    "            assert top_pair_reduced.shape[0] == new_tokens.shape[0]\n",
    "        \n",
    "        # 1) Replace one all even pairs\n",
    "        current_overlap_pairs = self.extract_current_gate_overlap_pairs(current_tensor, odd_pairs=False)\n",
    "        current_tensor = self.replace_current_overlap_pairs(current_tensor, current_overlap_pairs, top_pair, top_pair_reduced, new_tokens, odd_pairs=False)\n",
    "    \n",
    "        # 2) Then Replace one all odd pairs\n",
    "        current_overlap_pairs = self.extract_current_gate_overlap_pairs(current_tensor, odd_pairs=True)\n",
    "        current_tensor = self.replace_current_overlap_pairs(current_tensor, current_overlap_pairs, top_pair, top_pair_reduced, new_tokens, odd_pairs=True)\n",
    "        \n",
    "        return current_tensor\n",
    "    \n",
    "    def extract_current_gate_overlap_pairs(self, current_tensor, odd_pairs: bool = True):\n",
    "        # Extract overlap_pairs\n",
    "        # ToDo optimize loops\n",
    "\n",
    "        seq = current_tensor.shape[-1]\n",
    "        seq_half = seq // 2 \n",
    "        assert seq % 2 == 0\n",
    "\n",
    "        overlap_pairs = []\n",
    "        for current_tensor_i in current_tensor:\n",
    "            _overlap_pairs = []\n",
    "\n",
    "            if odd_pairs:\n",
    "                for t in range(seq_half-1):\n",
    "                    _overlap_pairs.append(current_tensor_i[:, 1+2*t:1+2*(t+1)])\n",
    "            else:\n",
    "                for t in range(seq_half):\n",
    "                    _overlap_pairs.append(current_tensor_i[:, 2*t:2*(t+1)])\n",
    "                \n",
    "            overlap_pairs.append(torch.stack(_overlap_pairs))\n",
    "            \n",
    "        overlap_pairs = torch.stack(overlap_pairs)\n",
    "        return overlap_pairs\n",
    "        \n",
    "    def replace_current_overlap_pairs(self, current_tensor, overlap_pairs, top_pair, top_pair_reduced, new_tokens, odd_pairs):\n",
    "\n",
    "        overlap_pairs_std = self.standardize_overlap_pairs(overlap_pairs)\n",
    "        is_top_overlap_pair = (overlap_pairs_std==top_pair).all(dim=(-1,-2), keepdim=False)\n",
    "\n",
    "        new_tensor = torch.full_like(current_tensor, self.padding_token)\n",
    "        \n",
    "        for i in range(is_top_overlap_pair.shape[0]): #ToDo: this loop can be put in parallel! is batch dim\n",
    "            t = 1 if odd_pairs else 0\n",
    "            \n",
    "            for j in range(is_top_overlap_pair.shape[1]):\n",
    "        \n",
    "                if is_top_overlap_pair[i, j]: #replace\n",
    "                      \n",
    "                    new_col = torch.zeros((current_tensor.shape[1]), dtype=overlap_pairs.dtype, device=overlap_pairs.device)\n",
    "            \n",
    "                    for new_token, top_pair_reduced_i in zip(new_tokens, top_pair_reduced):\n",
    "                        ind = (overlap_pairs[i, j]==top_pair_reduced_i).all(-1)\n",
    "                        new_col = torch.where(ind, new_token, new_col)\n",
    "                    \n",
    "                    new_col = new_col.unsqueeze(-1)\n",
    "                    \n",
    "                    tp1 = t + 1\n",
    "                 \n",
    "                else: #just copy old\n",
    "                    new_col = overlap_pairs[i, j]\n",
    "                    tp1 = t + 2\n",
    "            \n",
    "                new_tensor[i, :, t:tp1] = new_col\n",
    "                t = tp1\n",
    "\n",
    "            if odd_pairs:\n",
    "                # copy first and last col\n",
    "                new_tensor[..., 0]  = current_tensor[..., 0]\n",
    "                new_tensor[..., -1] = current_tensor[..., -1]\n",
    "            \n",
    "        return new_tensor         \n",
    "        \n",
    "    #---------------------------------------\n",
    "    # Find new pairs\n",
    "    \n",
    "    def extract_new_gate_overlap_pairs(self, current_tensor):\n",
    "        #current_tensor = current_tensor.abs()\n",
    "\n",
    "        isgate_token = 1 - torch.isin(current_tensor.abs(), self.not_gates_tokens.to(current_tensor.device)).int()\n",
    "\n",
    "        # These are postions of the pairs (therefore shape-1) in which we have an overlap\n",
    "        overlaps = isgate_token[..., :-1] + isgate_token[..., 1:]\n",
    "        overlaps = (overlaps>1).int()\n",
    "\n",
    "        # Number of overlaps two gates have!  we can say here only take 2 overlaps, or min 2, or min 1, eg..    ->  0 means parallel!!\n",
    "        overlaps_cnt = torch.count_nonzero(overlaps, dim=1) \n",
    "        overlaps_ind = (overlaps_cnt>0)\n",
    "    \n",
    "        # Extract overlap_pairs\n",
    "        # ToDo optimize loops\n",
    "        \n",
    "        overlap_pairs = []\n",
    "        for current_tensor_i, overlaps_ind_i in zip(current_tensor, overlaps_ind):\n",
    "            for t in range(current_tensor_i.shape[-1]-1):\n",
    "                if overlaps_ind_i[t]:\n",
    "                    overlap_pairs.append(current_tensor_i[:, t:t+2])\n",
    "\n",
    "        overlap_pairs = torch.stack(overlap_pairs)\n",
    "        return overlap_pairs\n",
    "\n",
    "    def standardize_overlap_pairs(self, overlap_pairs):\n",
    "        # Now we convert to std form, where the 1st gate gives the main order and the 2nd the secondory, this should remove all(?) redundant combinations!\n",
    "\n",
    "        # 1) sort inner SECOND gate such that gate 2 is always on top\n",
    "        inner_sorted_gate2, inner_sorted_gate2_indices =   torch.sort(overlap_pairs[..., 1], dim=-1, descending=True, stable=False)\n",
    "        inner_sorted_gate1                             = torch.gather(overlap_pairs[..., 0], dim=-1, index=inner_sorted_gate2_indices)\n",
    "        \n",
    "        inner_overlap_pairs = torch.stack((inner_sorted_gate1, inner_sorted_gate2), dim=-1)\n",
    "        \n",
    "        # 2) sort outer FISRT gate such that gate 1 is always on top, NOTE WE NEED STABLE SORT TO CONSERVE INNER ORDER\n",
    "        outer_sorted_gate1, outer_sorted_gate1_indices =   torch.sort(inner_overlap_pairs[..., 0], dim=-1, descending=True, stable=True)\n",
    "        outer_sorted_gate2                             = torch.gather(inner_overlap_pairs[..., 1], dim=-1, index=outer_sorted_gate1_indices)\n",
    "        \n",
    "        overlap_pairs_std_form = torch.stack((outer_sorted_gate1, outer_sorted_gate2), dim=-1)\n",
    "\n",
    "        return overlap_pairs_std_form.contiguous()\n",
    "\n",
    "    def get_topk_pairs(self, overlap_pairs, k):\n",
    "        # Now we can easily count the unique valid pairs! \n",
    "        pot_pairs, pot_pairs_cnts = overlap_pairs.unique(dim=0, return_counts=True)\n",
    "        \n",
    "        # Get topk best pairs\n",
    "        topv, topi = torch.topk(pot_pairs_cnts, k)\n",
    "        top_pairs  = pot_pairs[topi]\n",
    "        \n",
    "        return top_pairs, topv\n",
    "\n",
    "    #---------------------------------------\n",
    "    # Encoding\n",
    "\n",
    "    def encode(self, tensors):\n",
    "        # just replay all the pair replacements from learn, i.e. the vocab\n",
    "\n",
    "        s = tensors.shape[1]\n",
    "        current_tensor = tensors\n",
    "\n",
    "        for new_tokens, top_pair in tqdm(self.token_lookup_raw.items()):\n",
    "            top_pair = self.standardize_vocab_pair(top_pair, s, sort=True)\n",
    "            new_tokens = torch.tensor(new_tokens, device=top_pair.device, dtype=top_pair.dtype)\n",
    "            \n",
    "            current_tensor = self.learn_step(current_tensor, top_pair, new_tokens=new_tokens)\n",
    "\n",
    "        return current_tensor\n",
    "\n",
    "    def standardize_vocab_pair(self, vocab_pair, s, sort: bool = True):\n",
    "        \n",
    "        if vocab_pair.shape[0]<2: # repeat for special gadgets which have full symetric sequential connection\n",
    "            vocab_pair = vocab_pair.repeat(2, 1)\n",
    "        \n",
    "        vocab_pair = F.pad(vocab_pair, [0, 0, 0, s-vocab_pair.shape[0]]) # pad to full systemsize to have nice plotting\n",
    "\n",
    "        if sort:\n",
    "            vocab_pair = self.standardize_overlap_pairs(vocab_pair)\n",
    "            \n",
    "        return vocab_pair.contiguous()\n",
    "        \n",
    "    #---------------------------------------\n",
    "    # Decoding\n",
    "\n",
    "    def unpack_col(self, col):\n",
    "        # col is [s, 1]\n",
    "        s, _ = col.shape\n",
    "    \n",
    "        current_tokens = col.unique()\n",
    "        current_tokens = current_tokens[current_tokens!=0]\n",
    "        k = tuple(current_tokens.tolist())\n",
    "        \n",
    "        if k in self.token_lookup:\n",
    "    \n",
    "            # Unpack one col\n",
    "            unpacked   = torch.zeros((s, 2), dtype=col.dtype, device=col.device)\n",
    "            new_config = self.token_lookup[k]\n",
    "            \n",
    "            for current_token, new_config_i in zip(current_tokens, new_config):\n",
    "                ind      = (col==current_token)\n",
    "                unpacked = torch.where(ind, new_config_i, unpacked)\n",
    "                 \n",
    "            # Repeat unpacking for both new cols\n",
    "            col1, col2 = unpacked.chunk(2, dim=-1)\n",
    "    \n",
    "            unpacked1 = self.unpack_col(col1)\n",
    "            unpacked2 = self.unpack_col(col2)\n",
    "    \n",
    "            unpacked = torch.cat([unpacked1, unpacked2], dim=-1)\n",
    "            return unpacked\n",
    "        \n",
    "        return col \n",
    "\n",
    "    def decode(self, tensor, cut_padding: bool = False):\n",
    "        # split into cols we unpack, then recursively\n",
    "        # tensor ... [s, t]\n",
    "        assert tensor.dim() == 2\n",
    "        \n",
    "        cols     = tensor.chunk(tensor.shape[-1], dim=-1)\n",
    "        unpacked = torch.cat([self.unpack_col(col) for col in cols], dim=-1)\n",
    "\n",
    "        if cut_padding:\n",
    "            # Cut from right as this was added padding in packing\n",
    "            unpacked = unpacked[..., :tensor.shape[-1]]\n",
    "        \n",
    "        return unpacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035f5a62-65c7-45fa-8853-1bb242594319",
   "metadata": {},
   "source": [
    "### Plot learned tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce69148d-37df-47e3-9c63-5c9149d938ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T11:14:45.764089Z",
     "iopub.status.busy": "2025-06-01T11:14:45.764089Z",
     "iopub.status.idle": "2025-06-01T11:14:45.768360Z",
     "shell.execute_reply": "2025-06-01T11:14:45.768360Z",
     "shell.execute_reply.started": "2025-06-01T11:14:45.764089Z"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def sort_config(vocab_config):\n",
    "    \"\"\"Sort a vocab_config for nicer plotting.\"\"\"\n",
    "    \n",
    "    t = vocab_config.shape[-1]\n",
    "    all_inds = set(range(t))\n",
    "\n",
    "    # Sort one ind, gather the rest\n",
    "    for i in reversed(range(t)):\n",
    "        gather_inds = all_inds - {i}\n",
    "\n",
    "        sorted_gates = [None] * t\n",
    "        \n",
    "        sorted_gate_i, sorted_gate_i_indices = torch.sort(vocab_config[..., i], dim=-1, descending=True, stable=True)\n",
    "        sorted_gates[i] = sorted_gate_i\n",
    "        \n",
    "        for gather_ind in gather_inds:\n",
    "            sorted_gates[gather_ind] = torch.gather(vocab_config[..., gather_ind], dim=-1, index=sorted_gate_i_indices)\n",
    "\n",
    "        vocab_config = torch.stack(sorted_gates, dim=-1)\n",
    "    \n",
    "    return vocab_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aca2f79-49b4-43d4-8c8e-6d5759f77db0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T11:14:45.769372Z",
     "iopub.status.busy": "2025-06-01T11:14:45.769372Z",
     "iopub.status.idle": "2025-06-01T11:14:45.774045Z",
     "shell.execute_reply": "2025-06-01T11:14:45.774045Z",
     "shell.execute_reply.started": "2025-06-01T11:14:45.769372Z"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_topk_depth_unpacked(gate_pair_tokenizer, s, use_raw=False, standardize=True):\n",
    "    \"\"\"Useful for plotting.\"\"\"\n",
    "    \n",
    "    # Sort into depths\n",
    "    unpacked_vocab_configs_depths      = {}\n",
    "    unpacked_vocab_configs_cnts_depths = {}\n",
    "\n",
    "    if use_raw:\n",
    "        iters = zip(gate_pair_tokenizer.token_lookup_raw.items(), gate_pair_tokenizer.token_cnts.values())\n",
    "    else:\n",
    "        iters = zip(gate_pair_tokenizer.token_lookup.items(), gate_pair_tokenizer.token_cnts.values())\n",
    "    \n",
    "    for (vocab_tokens, vocab_config), vocab_config_cnts in tqdm(iters, total=len(gate_pair_tokenizer.token_cnts)):\n",
    "    \n",
    "        tok = vocab_tokens[0]\n",
    "        token_depth = gate_pair_tokenizer.token_depth[tok]\n",
    "\n",
    "        if standardize:\n",
    "            vocab_config = gate_pair_tokenizer.standardize_vocab_pair(vocab_config, s, sort=False)\n",
    "        unpacked_vocab_config = gate_pair_tokenizer.decode(vocab_config)\n",
    "    \n",
    "        #--------\n",
    "        unpacked_vocab_config = sort_config(unpacked_vocab_config)\n",
    "     \n",
    "        if token_depth not in unpacked_vocab_configs_depths:\n",
    "            unpacked_vocab_configs_depths[token_depth]      = []\n",
    "            unpacked_vocab_configs_cnts_depths[token_depth] = []\n",
    "            \n",
    "        unpacked_vocab_configs_depths[token_depth].append(unpacked_vocab_config)\n",
    "        unpacked_vocab_configs_cnts_depths[token_depth].append(vocab_config_cnts)\n",
    "\n",
    "    return unpacked_vocab_configs_depths, unpacked_vocab_configs_cnts_depths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f26a8-ac40-4e91-8c0e-1ef07a0fd4f4",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0474216-8e0c-4ba7-9a37-571ac7d8e82c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T11:14:45.775053Z",
     "iopub.status.busy": "2025-06-01T11:14:45.775053Z",
     "iopub.status.idle": "2025-06-01T11:14:46.709412Z",
     "shell.execute_reply": "2025-06-01T11:14:46.709412Z",
     "shell.execute_reply.started": "2025-06-01T11:14:45.775053Z"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
