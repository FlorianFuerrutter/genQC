{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8980c24-d62e-462b-ba89-3195cfdcc374",
   "metadata": {},
   "source": [
    "# Unitary CLIP Pipeline\n",
    "\n",
    "> Pipeline for contrastive pre-training of an unitary encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8832bdd-f61c-44e1-8619-a9cb352ba768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp pipeline.unitary_clip_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06272f6f-b4e3-4504-a90a-feebbf6ad821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from genQC.imports import *\n",
    "from genQC.pipeline.pipeline import Pipeline\n",
    "from genQC.utils.config_loader import *\n",
    "from genQC.models.config_model import ConfigModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea10ee8-e231-421c-8fca-3c5dc3e57743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UnitaryCLIPPipeline(Pipeline):\n",
    "    def __init__(self, \n",
    "                 model: nn.Module,\n",
    "                 device: torch.device) -> None:\n",
    "        super().__init__(model, device)   \n",
    "        \n",
    "        self.loss   = nn.CrossEntropyLoss()\n",
    "        self.device = device\n",
    "\n",
    "    #------------------------------------\n",
    "    \n",
    "    add_config = {}\n",
    "    \n",
    "    def params_config(self, save_path: str) -> dict:         \n",
    "        params_config = {}\n",
    "                \n",
    "        params_config[\"model\"]                = self.model.get_config(save_path=save_path+\"model\")\n",
    "        params_config[\"unitary_text_encoder\"] = self.model.unitary_text_encoder.get_config(save_path=None)\n",
    "        params_config[\"circuit_encoder\"]      = self.model.circuit_encoder.get_config(save_path=None)\n",
    "        \n",
    "        params_config[\"device\"]                = str(self.device)\n",
    "        params_config[\"add_config\"]            = self.add_config\n",
    "        \n",
    "        return params_config\n",
    "\n",
    "    def store_pipeline(self, config_path: str, save_path: str):\n",
    "        super().store_pipeline(config_path, save_path)\n",
    "        config = self.get_config(save_path)\n",
    "        save_dict_yaml(config, config_path+\"config.yaml\")\n",
    "               \n",
    "        self.model.store_model(config_path=None, save_path=save_path+\"model\")\n",
    "\n",
    "    @staticmethod\n",
    "    def from_config_file(config_path, device: torch.device, save_path: str=None):    \n",
    "        config = load_config(config_path+\"config.yaml\")   \n",
    "        config = config_to_dict(config)\n",
    "\n",
    "        def _get_save_path(config_save_path, appendix):\n",
    "            _save_path = default(save_path, config_path) + appendix\n",
    "            if \"save_path\" in config_save_path:\n",
    "                _save_path = config_save_path[\"save_path\"]\n",
    "            return _save_path  \n",
    "\n",
    "        if exists(device):\n",
    "            config[\"params\"][\"device\"] = device\n",
    "            config[\"params\"][\"model\"][\"params\"][\"text_encoder_config\"][\"device\"] = device\n",
    "\n",
    "        unitary_text_encoder = ConfigModel.from_config(config[\"params\"].pop(\"unitary_text_encoder\", None), device, None) \n",
    "        circuit_encoder      = ConfigModel.from_config(config[\"params\"].pop(\"circuit_encoder\", None), device, None) \n",
    "        \n",
    "        config[\"params\"][\"model\"][\"params\"][\"unitary_text_encoder\"] = unitary_text_encoder\n",
    "        config[\"params\"][\"model\"][\"params\"][\"circuit_encoder\"]      = circuit_encoder\n",
    "        config[\"params\"][\"model\"] = ConfigModel.from_config(config[\"params\"][\"model\"], device, _get_save_path(config[\"params\"][\"model\"], \"model\"))\n",
    "\n",
    "        add_config = config[\"params\"].pop(\"add_config\", None)\n",
    "\n",
    "        pipeline = instantiate_from_config(config)\n",
    "        \n",
    "        if exists(pipeline.add_config):\n",
    "            pipeline.add_config = add_config\n",
    "        \n",
    "        return pipeline\n",
    "    \n",
    "    #------------------------------------\n",
    "    # Inference functions\n",
    "        \n",
    "    @torch.no_grad()    \n",
    "    def __call__(self, tokens: torch.Tensor, params: torch.Tensor, y: torch.Tensor, U: torch.Tensor, softmax=True) -> torch.Tensor:\n",
    "        #compute the score of img-label pairs for classification!!\n",
    "        self.model.eval()\n",
    "        \n",
    "        scores = self.model(tokens=tokens, params=params, y=y, U=U) #[b, b]  \n",
    "        \n",
    "        if softmax: \n",
    "            scores = F.softmax(scores, dim-1)\n",
    "        \n",
    "        return scores\n",
    "        \n",
    "    #------------------------------------\n",
    "    # Training functions\n",
    "                \n",
    "    def get_loss(self, tokens: torch.Tensor, params: torch.Tensor, y: torch.Tensor, U: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        scores = self.model(tokens=tokens, params=params, y=y, U=U) #[b, b]\n",
    "        \n",
    "        #scores is: I=unitary_text   T=circuit\n",
    "        #--------------------------------\n",
    "        #| I1*T1   I1*T2   I1*T3   ...\n",
    "        #| I2*T1\n",
    "        #| I3*T1\n",
    "        # ...\n",
    "        #--------------------------------\n",
    "\n",
    "        target = torch.arange(scores.shape[0], device=scores.device)\n",
    "        \n",
    "        loss_unitary_text = self.loss(scores  , target)\n",
    "        loss_circuit      = self.loss(scores.T, target)\n",
    "        \n",
    "        #symmetric loss\n",
    "        loss = (loss_unitary_text + loss_circuit) / 2.0\n",
    "                \n",
    "        return loss\n",
    "        \n",
    "    def train_step(self, data, **kwargs): \n",
    "        tokens, y, params, U = data \n",
    "        \n",
    "        tokens = tokens.to(self.device)  \n",
    "        params = params.to(self.device)   \n",
    "        y = y.to(self.device)    \n",
    "        U = U.to(torch.float32).to(self.device)\n",
    "        \n",
    "        loss = self.get_loss(tokens=tokens, params=params, y=y, U=U)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f26a8-ac40-4e91-8c0e-1ef07a0fd4f4",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0474216-8e0c-4ba7-9a37-571ac7d8e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
