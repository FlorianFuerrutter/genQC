{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8980c24-d62e-462b-ba89-3195cfdcc374",
   "metadata": {},
   "source": [
    "# DDPMScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ff99d-293b-4e7d-b425-6af2856e2935",
   "metadata": {},
   "source": [
    "Denoising diffusion probabilistic models [(DDPM)](https://arxiv.org/abs/2006.11239): reverse beta is fixed and diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8832bdd-f61c-44e1-8619-a9cb352ba768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp scheduler.scheduler_ddpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06272f6f-b4e3-4504-a90a-feebbf6ad821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from genQC.imports import *\n",
    "from genQC.scheduler.scheduler import Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0475b1-e0aa-42eb-9f56-12c131ef868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class DDPMSchedulerOutput:\n",
    "    prev_sample: torch.FloatTensor\n",
    "    pred_original_sample: Optional[torch.FloatTensor] = None\n",
    "    \n",
    "class DDPMScheduler(Scheduler):\n",
    "    \"\"\"A `Scheduler` implementing [(DDPM)](https://arxiv.org/abs/2006.11239)\"\"\"\n",
    "    \n",
    "    non_blocking = False\n",
    "    \n",
    "    def __init__(self, \n",
    "                 device: Union[str, torch.device],     \n",
    "                 num_train_timesteps: int = 1000,\n",
    "                 beta_start: float = 0.0001,\n",
    "                 beta_end: float = 0.02,\n",
    "                 beta_schedule: str = \"linear\",\n",
    "                 input_perturbation = 0.1\n",
    "                ):    \n",
    "        super().__init__()\n",
    "        self.device = device        \n",
    "        self.num_train_timesteps = torch.tensor(num_train_timesteps)\n",
    "        self.num_inference_steps = torch.tensor(num_train_timesteps)\n",
    "        \n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.beta_schedule = beta_schedule\n",
    "\n",
    "        self.timesteps = torch.from_numpy(np.arange(0, num_train_timesteps)[::-1].copy().astype(np.int64)) #careful is defined reversed for easy denoising looping\n",
    "            \n",
    "        if beta_schedule == \"linear\":\n",
    "            self.betas = torch.linspace(beta_start, beta_end, num_train_timesteps, dtype=torch.float32)\n",
    "            \n",
    "        elif beta_schedule == \"linear_sqrt\":\n",
    "            self.betas = torch.linspace(beta_start ** 0.5, beta_end ** 0.5, num_train_timesteps, dtype=torch.float32) ** 2\n",
    "                      \n",
    "        elif beta_schedule == \"cos_alpha\":  #cosine-based-variance                      \n",
    "            f = lambda t: np.cos((t/self.num_train_timesteps + 0.008)*np.pi/2.016)**2 \n",
    "            _betas = []            \n",
    "            for i in range(self.num_train_timesteps):                           \n",
    "                _betas.append(min(1.0-(f(i+1.0)/f(i)),0.999))                \n",
    "            self.betas = torch.tensor(_betas, dtype=torch.float32)                       \n",
    "        else:\n",
    "            raise NotImplementedError(f\"{beta_schedule} does is not implemented for {self.__class__}\")\n",
    "              \n",
    "        self.sigmas = torch.sqrt(self.betas)\n",
    "                 \n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)  \n",
    "        \n",
    "        ## Is this used anymore?\n",
    "        self.sqrt_alphas                   = torch.sqrt(self.alphas)  \n",
    "        self.sqrt_alphas_cumprod           = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - self.alphas_cumprod)\n",
    "        ##\n",
    "        \n",
    "        #----------\n",
    "        # Input Perturbation Reduces Exposure Bias in Diffusion Models\n",
    "        # https://arxiv.org/pdf/2301.11706.pdf\n",
    "        \n",
    "        self.input_perturbation = input_perturbation\n",
    "        \n",
    "        #----------\n",
    "        \n",
    "        self.to_device(self.device)\n",
    "    \n",
    "    @property\n",
    "    def params_config(self):         \n",
    "        params_config = {}           \n",
    "        params_config[\"device\"]              = str(self.device)\n",
    "        params_config[\"num_train_timesteps\"] = self.num_train_timesteps.item()\n",
    "        params_config[\"beta_start\"]          = self.beta_start\n",
    "        params_config[\"beta_end\"]            = self.beta_end\n",
    "        params_config[\"beta_schedule\"]       = self.beta_schedule\n",
    "        params_config[\"input_perturbation\"]  = self.input_perturbation            \n",
    "        return params_config\n",
    "    \n",
    "    def to_device(self, device: Union[str, torch.device], non_blocking=False):\n",
    "        #non_blocking = self.non_blocking\n",
    "        \n",
    "        self.device                        = device\n",
    "        self.alphas_cumprod                = self.alphas_cumprod.to(device, non_blocking=non_blocking)\n",
    "        self.sqrt_alphas_cumprod           = self.sqrt_alphas_cumprod.to(device, non_blocking=non_blocking)\n",
    "        self.sqrt_one_minus_alphas_cumprod = self.sqrt_one_minus_alphas_cumprod.to(device, non_blocking=non_blocking)\n",
    "        self.sigmas                        = self.sigmas.to(device, non_blocking=non_blocking)\n",
    "        self.sqrt_alphas                   = self.sqrt_alphas.to(device, non_blocking=non_blocking)\n",
    "        self.betas                         = self.betas.to(device, non_blocking=non_blocking)\n",
    "        self.num_train_timesteps           = self.num_train_timesteps.to(device, non_blocking=non_blocking)\n",
    "        self.num_inference_steps           = self.num_inference_steps.to(device, non_blocking=non_blocking)\n",
    "        \n",
    "    #------------------------------------\n",
    "    # Inference functions\n",
    "    \n",
    "    def set_timesteps(self, num_inference_steps: int):        \n",
    "        if num_inference_steps >= self.num_train_timesteps: raise ValueError(\"num_inference_steps >= self.num_train_timesteps\")     \n",
    "        self.num_inference_steps = torch.tensor(num_inference_steps)\n",
    "        step_ratio = self.num_train_timesteps // self.num_inference_steps\n",
    "        timesteps = (np.arange(0, num_inference_steps) * step_ratio.item()).round()[::-1].copy().astype(np.int64)\n",
    "        self.timesteps = torch.from_numpy(timesteps)\n",
    "               \n",
    "    def step(self,\n",
    "             model_output: torch.FloatTensor,\n",
    "             timesteps: Union[int, torch.IntTensor],\n",
    "             sample: torch.FloatTensor\n",
    "            ) -> DDPMSchedulerOutput:\n",
    "        \"\"\"Denoising step\"\"\"\n",
    "        \n",
    "        sqrt_alphas_cumprod = self.unsqueeze_vector_to_shape(self.sqrt_alphas_cumprod[timesteps], sample.shape)\n",
    "        sqrt_one_minus_alphas_cumprod = self.unsqueeze_vector_to_shape(self.sqrt_one_minus_alphas_cumprod[timesteps], sample.shape)\n",
    "           \n",
    "        sigmas      = self.unsqueeze_vector_to_shape(self.sigmas[timesteps], sample.shape)\n",
    "        sqrt_alphas = self.unsqueeze_vector_to_shape(self.sqrt_alphas[timesteps], sample.shape)\n",
    "        betas       = self.unsqueeze_vector_to_shape(self.betas[timesteps], sample.shape)\n",
    "      \n",
    "        non_zero_t = (timesteps!=0).float()\n",
    "    \n",
    "        #estimate the final img\n",
    "        x0 = (sample - sqrt_one_minus_alphas_cumprod * model_output) / sqrt_alphas_cumprod   #DDPM eq.15\n",
    "               \n",
    "        #less noisy latent     \n",
    "        noise = torch.randn(sample.shape, device=self.device) \n",
    "        noise = noise * non_zero_t.reshape(-1, 1, 1, 1)\n",
    "        \n",
    "        xt_coeff = betas / sqrt_one_minus_alphas_cumprod        \n",
    "        xt = (sample - xt_coeff * model_output) / sqrt_alphas + sigmas * noise \n",
    "        \n",
    "        return DDPMSchedulerOutput(prev_sample=xt, pred_original_sample=x0)\n",
    "\n",
    "    def add_noise_LEdit(self, original_samples: torch.FloatTensor):\n",
    "        # LEDITS: Real Image Editing with DDPM Inversion and Semantic Guidance; Note: SEGA (Semantic Guidance) is just multiple negative promts with a pixel based weight\n",
    "        # https://arxiv.org/pdf/2307.00522.pdf\n",
    "\n",
    "        noisy_latents = []\n",
    "        noises        = []\n",
    "\n",
    "        noisy_latent_t = original_samples\n",
    "        \n",
    "        for t in self.timesteps[::-1]: #start from no noise and diffuse in non analytic fashion\n",
    "            noise_t        = torch.randn_like(noise)   \n",
    "            alpha_t        = self.unsqueeze_vector_to_shape(self.alphas[t], original_samples.shape)    \n",
    "            noisy_latent_t = torch.sqrt(alpha_t) * noisy_latent_t + torch.sqrt(1.0 - alpha_t) * noise_t       \n",
    "\n",
    "            noises.append(noise_t)\n",
    "            noisy_latents.append(noisy_latent_t)\n",
    "        \n",
    "        return noisy_latents[::-1], noises[::-1] # invert to self.timestep definition\n",
    "    \n",
    "    #------------------------------------\n",
    "    # Training functions\n",
    "        \n",
    "    def add_noise(self,\n",
    "                  original_samples: torch.FloatTensor,\n",
    "                  noise: torch.FloatTensor,\n",
    "                  timesteps: torch.IntTensor,\n",
    "                 ) -> torch.FloatTensor:\n",
    "            \n",
    "        alphas_cumprod = self.unsqueeze_vector_to_shape(self.alphas_cumprod[timesteps], original_samples.shape)        \n",
    "        noisy_latents = torch.sqrt(alphas_cumprod) * original_samples + torch.sqrt(1.0 - alphas_cumprod) * noise       \n",
    "        \n",
    "        if self.input_perturbation is not None:\n",
    "            noisy_latents = noisy_latents + torch.sqrt(1.0 - alphas_cumprod) * torch.randn_like(noise) * self.input_perturbation\n",
    "        \n",
    "        return noisy_latents  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0474216-8e0c-4ba7-9a37-571ac7d8e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
