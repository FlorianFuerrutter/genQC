{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8980c24-d62e-462b-ba89-3195cfdcc374",
   "metadata": {},
   "source": [
    "# DDIMScheduler "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45487a0f-d029-461b-853e-9b59a9bc6d3e",
   "metadata": {},
   "source": [
    "Denoising diffusion implicit models [(DDIM)](https://arxiv.org/abs/2010.02502)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8832bdd-f61c-44e1-8619-a9cb352ba768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp scheduler.scheduler_ddim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06272f6f-b4e3-4504-a90a-feebbf6ad821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from genQC.imports import *\n",
    "from genQC.scheduler.scheduler_ddpm import DDPMScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0475b1-e0aa-42eb-9f56-12c131ef868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class DDIMSchedulerOutput:\n",
    "    prev_sample: torch.FloatTensor\n",
    "    pred_original_sample: Optional[torch.FloatTensor] = None\n",
    "    \n",
    "class DDIMScheduler(DDPMScheduler):\n",
    "    \"\"\"A `Scheduler` implementing [(DDIM)](https://arxiv.org/abs/2010.02502).\"\"\"\n",
    "    def __init__(self, \n",
    "                 device: Union[str, torch.device],     \n",
    "                 num_train_timesteps: int = 1000,\n",
    "                 beta_start: float = 0.0001,\n",
    "                 beta_end: float = 0.02,\n",
    "                 beta_schedule: str = \"linear\",\n",
    "                 input_perturbation = 0.1,\n",
    "                 eta: float = 0\n",
    "                ):    \n",
    "        super().__init__(device, num_train_timesteps, beta_start, beta_end, beta_schedule, input_perturbation)\n",
    "        self.eta = eta\n",
    "        \n",
    "        #for stable diff ddim\n",
    "        set_alpha_to_one = True  # False \n",
    "        steps_offset     = 0     # 1\n",
    "            \n",
    "        self.steps_offset        = steps_offset\n",
    "        self.final_alpha_cumprod = torch.tensor(1.0) if set_alpha_to_one else self.alphas_cumprod[0]\n",
    "     \n",
    "    @property\n",
    "    def params_config(self):         \n",
    "        params_config = super().params_config\n",
    "        params_config[\"eta\"] = self.eta\n",
    "        return params_config\n",
    "    \n",
    "    #------------------------------------\n",
    "    # Inference functions\n",
    "    \n",
    "    def set_timesteps(self, num_inference_steps: int):        \n",
    "        super().set_timesteps(num_inference_steps)   \n",
    "        self.timesteps += self.steps_offset\n",
    "    \n",
    "    clamp_style = None # one of: None, \"static\", \"dynamic\"\n",
    "    \n",
    "    def step(self,         \n",
    "             model_output: torch.FloatTensor,\n",
    "             timesteps: Union[int, torch.IntTensor],\n",
    "             sample: torch.FloatTensor\n",
    "            ) -> DDIMSchedulerOutput:\n",
    "        \"\"\"Denoising step\"\"\"\n",
    "        \n",
    "        prev_timesteps = timesteps - self.num_train_timesteps // self.num_inference_steps\n",
    "        \n",
    "        #get variance sched\n",
    "        alphas_cumprod     = self.unsqueeze_vector_to_shape(self.alphas_cumprod[timesteps], sample.shape)\n",
    "        alphas_cumprod_tm1 = self.unsqueeze_vector_to_shape(self.alphas_cumprod[prev_timesteps], sample.shape)\n",
    "                       \n",
    "        #fix negative timesteps to self.final_alpha_cumprod        \n",
    "        non_zero_tm1 = (prev_timesteps>=0.0).float()      \n",
    "        non_zero_tm1 = self.unsqueeze_vector_to_shape(non_zero_tm1, sample.shape)\n",
    "        alphas_cumprod_tm1 = alphas_cumprod_tm1 * non_zero_tm1 + (1.0 - non_zero_tm1) *  self.final_alpha_cumprod  \n",
    "                              \n",
    "        #calc vars\n",
    "        betas_cumprod     = 1.0 - alphas_cumprod\n",
    "        betas_cumprod_tm1 = 1.0 - alphas_cumprod_tm1\n",
    "            \n",
    "        #estimate predicted sample\n",
    "        x0 = (sample - betas_cumprod.sqrt() * model_output) / alphas_cumprod.sqrt()\n",
    "        \n",
    "        if   self.clamp_style == None: pass\n",
    "        elif self.clamp_style == \"static\":  x0 = torch.clamp(x0, -1, 1)\n",
    "        elif self.clamp_style == \"dynamic\": raise NotImplementedError(\"clamp_style == 'dynamic'\")\n",
    "        else: raise NotImplementedError(\"self.clamp_style has to be one of: None, 'static', 'dynamic'\")       \n",
    "        #if self.num_train_timesteps // self.num_inference_steps > 1: x0 = torch.clamp(x0, -1, 1)\n",
    "    \n",
    "        #variance\n",
    "        variance = (betas_cumprod_tm1 / betas_cumprod) * (1.0 - alphas_cumprod / alphas_cumprod_tm1)\n",
    "        std      = self.eta * variance.sqrt()\n",
    "        \n",
    "        #direction to xt\n",
    "        dir_xt = ( betas_cumprod_tm1 - std.square() ).sqrt() * model_output\n",
    "    \n",
    "        #sample noise\n",
    "        noise = torch.randn(model_output.shape, device=self.device)\n",
    "    \n",
    "        #estimate the prev sample      \n",
    "        xtm1 = alphas_cumprod_tm1.sqrt() * x0 + dir_xt + std * noise\n",
    "        \n",
    "        # print(f\"{timesteps=} {prev_timesteps=} ;;;   x0:  {x0.mean()}+-{x0.std()}      xtm1:  {xtm1.mean()}+-{xtm1.std()}\")\n",
    "        \n",
    "        return DDIMSchedulerOutput(prev_sample=xtm1, pred_original_sample=x0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f26a8-ac40-4e91-8c0e-1ef07a0fd4f4",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0474216-8e0c-4ba7-9a37-571ac7d8e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
