{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8980c24-d62e-462b-ba89-3195cfdcc374",
   "metadata": {},
   "source": [
    "# DDIM Scheduler \n",
    "\n",
    "> Denoising diffusion implicit models [(DDIM)](https://arxiv.org/abs/2010.02502)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8832bdd-f61c-44e1-8619-a9cb352ba768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp scheduler.scheduler_ddim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06272f6f-b4e3-4504-a90a-feebbf6ad821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from genQC.imports import *\n",
    "from genQC.scheduler.scheduler_ddpm import DDPMScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d3b1e2-18d3-4cab-968c-853cb3469b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class DDIMSchedulerOutput:\n",
    "    prev_sample: torch.FloatTensor\n",
    "    pred_original_sample: Optional[torch.FloatTensor] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0475b1-e0aa-42eb-9f56-12c131ef868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export  \n",
    "class DDIMScheduler(DDPMScheduler):\n",
    "    \"\"\"A `Scheduler` implementing [(DDIM)](https://arxiv.org/abs/2010.02502).\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 device: Union[str, torch.device],     \n",
    "                 num_train_timesteps: int = 1000,\n",
    "                 beta_start: float = 0.0001,\n",
    "                 beta_end: float = 0.02,\n",
    "                 beta_schedule: str = \"linear\",\n",
    "                 input_perturbation = 0.1,\n",
    "                 prediction_type = \"epsilon\",\n",
    "                 enable_zero_terminal_snr = True,\n",
    "                 eta: float = 0\n",
    "                ):    \n",
    "        super().__init__(device, num_train_timesteps, beta_start, beta_end, beta_schedule, input_perturbation, prediction_type, enable_zero_terminal_snr)\n",
    "        self.eta = eta\n",
    "        \n",
    "        #for stable diff ddim\n",
    "        set_alpha_to_one = True  # False \n",
    "        steps_offset     = 0     # 1\n",
    "            \n",
    "        self.steps_offset        = steps_offset\n",
    "        self.final_alpha_cumprod = torch.tensor(1.0) if set_alpha_to_one else self.alphas_cumprod[0]\n",
    "     \n",
    "    @property\n",
    "    def params_config(self):         \n",
    "        params_config = super().params_config\n",
    "        params_config[\"eta\"] = self.eta\n",
    "        return params_config\n",
    "    \n",
    "    #------------------------------------\n",
    "    # Inference functions\n",
    "    \n",
    "    def set_timesteps(self, num_inference_steps: Optional[int] = None, timesteps: Optional[torch.Tensor] = None):       \n",
    "        super().set_timesteps(num_inference_steps=num_inference_steps, timesteps=timesteps)   \n",
    "        self.timesteps += self.steps_offset\n",
    "    \n",
    "    clamp_style = None # one of: None, \"static\", \"dynamic\"\n",
    "    \n",
    "    def step(self,         \n",
    "             model_output: torch.FloatTensor,\n",
    "             timesteps: Union[int, torch.IntTensor],\n",
    "             sample: torch.FloatTensor,\n",
    "             uncond_model_output: torch.FloatTensor = None # for CFG++\n",
    "            ) -> DDIMSchedulerOutput:\n",
    "        \"\"\"Denoising step\"\"\"\n",
    "        \n",
    "        prev_timesteps = timesteps - self.num_train_timesteps // self.num_inference_steps\n",
    "        # prev_timestep = torch.clamp(prev_timestep, 0, self.num_train_timesteps - 1) # NEW\n",
    "        \n",
    "        #get variance sched\n",
    "        alphas_cumprod     = self.unsqueeze_vector_to_shape(self.alphas_cumprod[timesteps], sample.shape)\n",
    "        alphas_cumprod_tm1 = self.unsqueeze_vector_to_shape(self.alphas_cumprod[prev_timesteps], sample.shape)\n",
    "                       \n",
    "        #fix negative timesteps to self.final_alpha_cumprod        \n",
    "        non_zero_tm1 = (prev_timesteps>=0.0).float()      \n",
    "        non_zero_tm1 = self.unsqueeze_vector_to_shape(non_zero_tm1, sample.shape)\n",
    "        alphas_cumprod_tm1 = alphas_cumprod_tm1 * non_zero_tm1 + (1.0 - non_zero_tm1) *  self.final_alpha_cumprod  \n",
    "                              \n",
    "        #calc vars\n",
    "        betas_cumprod     = 1.0 - alphas_cumprod\n",
    "        betas_cumprod_tm1 = 1.0 - alphas_cumprod_tm1\n",
    "\n",
    "        uncond_model_output = default(uncond_model_output, model_output)\n",
    "\n",
    "        if self.prediction_type == \"epsilon\":\n",
    "            #estimate predicted sample\n",
    "            x0  = (sample - betas_cumprod.sqrt() * model_output) / alphas_cumprod.sqrt()\n",
    "            eps = uncond_model_output #model_output\n",
    "            \n",
    "        elif self.prediction_type == \"v-type\":    \n",
    "            a = alphas_cumprod.sqrt()\n",
    "            b = betas_cumprod.sqrt()\n",
    "            \n",
    "            x0  = a * sample       - b * model_output \n",
    "            # eps = a * model_output + b * sample\n",
    "            eps = a * uncond_model_output + b * sample\n",
    "\n",
    "        elif self.prediction_type == \"x0\":\n",
    "            x0  = model_output\n",
    "            eps = (sample - alphas_cumprod.sqrt() * uncond_model_output) / betas_cumprod.sqrt()\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError(f\"{self.prediction_type} is not implemented for {self.__class__}.step()\")\n",
    "                     \n",
    "        if   self.clamp_style == None: pass\n",
    "        elif self.clamp_style == \"static\":  x0 = torch.clamp(x0, -1, 1)\n",
    "        elif self.clamp_style == \"dynamic\": raise NotImplementedError(\"clamp_style == 'dynamic'\")\n",
    "        else: raise NotImplementedError(\"self.clamp_style has to be one of: None, 'static', 'dynamic'\")       \n",
    "        #if self.num_train_timesteps // self.num_inference_steps > 1: x0 = torch.clamp(x0, -1, 1)\n",
    "    \n",
    "        #variance\n",
    "        variance = (betas_cumprod_tm1 / betas_cumprod) * (1.0 - alphas_cumprod / alphas_cumprod_tm1)\n",
    "        std      = self.eta * variance.sqrt()\n",
    "        \n",
    "        #direction to xt\n",
    "        dir_xt = (betas_cumprod_tm1 - std.square()).sqrt() * eps\n",
    "    \n",
    "        #sample noise\n",
    "        noise = torch.randn_like(x0)\n",
    "        \n",
    "        #estimate the prev sample      \n",
    "        xtm1 = alphas_cumprod_tm1.sqrt() * x0 + dir_xt + std * noise\n",
    "        \n",
    "        return DDIMSchedulerOutput(prev_sample=xtm1, pred_original_sample=x0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f26a8-ac40-4e91-8c0e-1ef07a0fd4f4",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0474216-8e0c-4ba7-9a37-571ac7d8e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
