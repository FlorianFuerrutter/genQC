{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7883f9c7-7102-4dd1-9a85-f3d2f1e653fc",
   "metadata": {},
   "source": [
    "# Config model\n",
    "\n",
    "> Model base class that handles loading and storing from/to config files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71cd37f-025e-411a-b830-16f4d512c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.config_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9efd6-abbc-4256-b0d9-7f7da64d81b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from genQC.imports import *\n",
    "from genQC.utils.config_loader import *\n",
    "from genQC.utils.misc_utils import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8228d0c-220e-400e-ae19-08dae3dd256a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e32385-485c-4bb0-863a-9b6390e8b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ConfigModel(nn.Module):\n",
    "    \"\"\"A basic `nn.Module` with IO functionality.\"\"\"\n",
    "    \n",
    "    def __init__(self, save_type=None): \n",
    "        super().__init__()\n",
    "        self.save_type = default(save_type, \"safetensors\")\n",
    "    \n",
    "    def freeze(self, freeze: bool = True):\n",
    "        if freeze: self.eval()\n",
    "        else:      self.train()\n",
    "\n",
    "        for param in self.parameters(): \n",
    "            param.requires_grad = not freeze \n",
    "\n",
    "        #Todo: add a debose/debug log here\n",
    "    \n",
    "    def unfreeze(self):\n",
    "        self.freeze(False)\n",
    "    \n",
    "    #---------------------\n",
    "\n",
    "    def check_save_type(self, save_path):\n",
    "        if exists(self.save_type) and exists(save_path):\n",
    "            if not save_path.endswith(f\".{self.save_type}\"):\n",
    "                save_path += f\".{self.save_type}\"\n",
    "        return save_path\n",
    " \n",
    "    def get_config(self, save_path=None, without_metadata=False):\n",
    "        if not without_metadata:       \n",
    "            config = {}\n",
    "            config[\"target\"]         = class_to_str(type(self)) \n",
    "            config[\"save_path\"]      = self.check_save_type(self.save_path) if hasattr(self, \"save_path\") and not exists(save_path) else self.check_save_type(save_path)\n",
    "            config[\"save_datetime\"]  = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "            config[\"save_type\"]      = self.save_type\n",
    "            config[\"params\"]         = self.params_config  \n",
    "        else:\n",
    "            config = self.params_config  \n",
    "        \n",
    "        self.config = config        \n",
    "        return config\n",
    "    \n",
    "    def store_model(self, config_path: str=None, save_path: str=None, without_metadata=False):        \n",
    "        \n",
    "        config = self.get_config(save_path, without_metadata)\n",
    "    \n",
    "        if exists(config_path):\n",
    "            if without_metadata: save_dataclass_yaml(config, config_path)\n",
    "            else               : save_dict_yaml(config, config_path)            \n",
    "        \n",
    "        if exists(save_path):\n",
    "            store_model_state_dict(self.state_dict(), self.check_save_type(save_path)) \n",
    "    \n",
    "    #---------------------\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_config(config, device: torch.device, save_path: str=None, verbose=True, silent=False, freeze: Optional[bool] = None):  \n",
    "        \"\"\"Use this if we have a loaded config. Maybe within other classes (e.g. pipeline and nested models)\"\"\"\n",
    "\n",
    "        _config = copy.deepcopy(config)\n",
    "        \n",
    "        if exists(device): _config[\"device\"] = device   # for loading sub-models\n",
    "        else:              device = _config.pop(\"device\", \"cpu\")\n",
    "\n",
    "        if exists(freeze):\n",
    "            _freeze = freeze\n",
    "      \n",
    "        else:\n",
    "            if \"is_frozen\" in _config: \n",
    "                _freeze = _config.pop(\"is_frozen\", None)\n",
    "                if not_exists(_freeze):\n",
    "                    raise RuntimeError(f\"The `is_frozen` flag in `config` is invalid. Please provide a boolean. `is_frozen` is: {freeze}\")\n",
    "            else:\n",
    "                _freeze = True\n",
    "                #print(f\"[INFO]: `{class_to_str(type(model))}`. No valid `is_frozen` flag in `config`. Model is frozen by default.\")\n",
    "        \n",
    "        #--------------------------------\n",
    "        # instantiate model\n",
    "        model = instantiate_from_config(_config)\n",
    "        model = model.to(device) \n",
    "        if not silent: print(f\"[INFO]: `{class_to_str(type(model))}` instantiated from given `config` on {device}.\")\n",
    "\n",
    "        #--------------------------------        \n",
    "        # load pretrained weights\n",
    "\n",
    "        model.save_type = _config.pop(\"save_type\", None)\n",
    "\n",
    "        if exists(model.save_type):\n",
    "            if not exists(save_path):            \n",
    "                if \"save_path\" in _config: \n",
    "                    save_path = model.check_save_type(_config[\"save_path\"])\n",
    "    \n",
    "                                      \n",
    "            if exists(save_path):        \n",
    "                state_dict = load_model_state_dict(model.check_save_type(save_path), device)\n",
    "                \n",
    "                m, u = model.load_state_dict(state_dict, strict=False)\n",
    "         \n",
    "                if len(m) + len(u) > 0 and verbose:\n",
    "                    print(f\"[WARNING]: missing keys: {m}\")\n",
    "                    print(f\"[WARNING]: unexpected keys: {u}\")\n",
    "    \n",
    "            else:\n",
    "                if not silent: print(f\"[INFO]: `{class_to_str(type(model))}`. No `save_path` provided. Found no key `save_path` in `config`. No state dict loaded.\")\n",
    "        else:\n",
    "            if not silent: print(f\"[INFO]: `{class_to_str(type(model))}`. Found no key `save_type` in `config`. No state dict loaded.\")\n",
    "        \n",
    "        #--------------------------------\n",
    "        # freeze    \n",
    "\n",
    "        if exists(_freeze):\n",
    "            model.freeze(_freeze)\n",
    "            if not silent: print(f\"[INFO]: `{class_to_str(type(model))}`. Freeze model: {_freeze}\")\n",
    "        else:\n",
    "            if not silent: print(f\"[INFO]: `{class_to_str(type(model))}`. No valid `is_frozen` flag in `config`. Model is frozen by default.\")\n",
    "\n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_config_file(config_path, device: torch.device, save_path: str=None):    \n",
    "        config = load_config(config_path)\n",
    "        return ConfigModel.from_config(config, device, save_path)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfd7536-56f8-479d-911f-3d62b427ecba",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f41df-ba6d-429d-a6a2-a9ff60a1ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
