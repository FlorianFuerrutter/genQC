{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7883f9c7-7102-4dd1-9a85-f3d2f1e653fc",
   "metadata": {},
   "source": [
    "# Conditional qc-UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee3aebc-8c22-47cf-b3bf-2edaacba9f00",
   "metadata": {},
   "source": [
    "Quantum circuit U-Net architecture predicting the noise for noisy quantum circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71cd37f-025e-411a-b830-16f4d512c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.unet_qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9efd6-abbc-4256-b0d9-7f7da64d81b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from genQC.imports import *\n",
    "from genQC.models.config_model import Config_Model\n",
    "import genQC.models.layers as layers\n",
    "import genQC.models.transformers as transformers\n",
    "from genQC.models.unitary_encoder import Unitary_encoder, Unitary_encoder_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b281615-6b19-4491-b381-b84c998551cd",
   "metadata": {},
   "source": [
    "## Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83beb94c-606e-4092-9e63-90be4d89a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UNet_block(nn.Module):\n",
    "    \"\"\"The basic block of the U-Net. Is conditioned via cross-attention in `SpatialTransformer` and addition of the time ebedding in `ResBlock2D_Conditional`.\"\"\"\n",
    "    def __init__(self, ch_in, ch_out, t_emb_size, cond_emb_size, num_heads=8, num_res_blocks=1, transformer_depth=1):\n",
    "        super().__init__()\n",
    "                                \n",
    "        self.resBlocks = nn.ModuleList() \n",
    "        for i in range(num_res_blocks):          \n",
    "            self.resBlocks.append(layers.ResBlock2D_Conditional(ch_in, ch_out, t_emb_size, kernel_size=(1, 3)))\n",
    "            ch_in = ch_out \n",
    "            \n",
    "        self.transformer_depth = transformer_depth\n",
    "        if self.transformer_depth > 0:\n",
    "            self.spatialTransformer = transformers.SpatialTransformer(ch_out, cond_emb_size, num_heads, transformer_depth)\n",
    "                   \n",
    "        self._init_weights()\n",
    "          \n",
    "    def _init_weights(self):\n",
    "        for resBlock in self.resBlocks:\n",
    "            resBlock.conv2.weight.data.zero_() \n",
    "                      \n",
    "    def forward(self, x, t_emb, c_emb, attn_mask, key_padding_mask):\n",
    "        for resBlock in self.resBlocks:\n",
    "            x = resBlock(x, t_emb)\n",
    "        \n",
    "        if self.transformer_depth > 0:\n",
    "            x = self.spatialTransformer(x, c_emb, attn_mask, key_padding_mask)   \n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117d85b-0839-4984-b311-819da477b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encoder definition of the U-Net.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_features, t_emb_size, cond_emb_size, num_heads, num_res_blocks, transformer_depths):\n",
    "        super().__init__()\n",
    "        self.enc_blocks = nn.ModuleList() \n",
    "        \n",
    "        in_ch = model_features[0]\n",
    "        for model_feature,heads,res_blocks,transformer_depth in zip(model_features[1:-1], num_heads[:-1], num_res_blocks[:-1], transformer_depths[:-1]):\n",
    "            out_ch         = model_feature            \n",
    "            enc_block      = UNet_block(in_ch, out_ch, t_emb_size, cond_emb_size, heads, res_blocks, transformer_depth)            \n",
    "            enc_block.down = layers.DownBlock2D(out_ch, out_ch, kernel_size=(1, 2), stride=(1, 2), padding=(0,0))       \n",
    "            in_ch          = out_ch \n",
    "        \n",
    "            self.enc_blocks.append(enc_block)\n",
    "    \n",
    "        self.mid_block = UNet_block(in_ch, model_features[-1], t_emb_size, cond_emb_size, num_heads[-1], num_res_blocks[-1], transformer_depths[-1])  # should be!\n",
    "        \n",
    "    def forward(self, x, t_emb, c_emb, attn_mask=None, key_padding_mask=None):        \n",
    "        ftrs = []       \n",
    "        for i,enc_block in enumerate(self.enc_blocks):\n",
    "            x = enc_block(x, t_emb, c_emb, attn_mask[i], key_padding_mask[i])  # attn_mask only in first layer!\n",
    "\n",
    "            ftrs.append(x)  \n",
    "            x = enc_block.down(x)\n",
    "    \n",
    "        x = self.mid_block(x, t_emb, c_emb, attn_mask[-1], key_padding_mask[-1])\n",
    "        ftrs.append(x)\n",
    "        \n",
    "        return ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544dbd78-d9b6-4bd9-bc49-92f04df1334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Decoder definition of the U-Net.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_features, t_emb_size, cond_emb_size, num_heads, num_res_blocks, transformer_depths):\n",
    "        super().__init__()\n",
    "        self.dec_blocks = nn.ModuleList()\n",
    "                     \n",
    "        in_ch = model_features[0]\n",
    "        for model_feature,heads,res_blocks, transformer_depth in zip(model_features[1:], num_heads[1:], num_res_blocks[1:], transformer_depths[1:]):\n",
    "            out_ch       = model_feature           \n",
    "            dec_block    = UNet_block(out_ch*2, out_ch, t_emb_size, cond_emb_size, heads, res_blocks, transformer_depth)            \n",
    "            dec_block.up = layers.UpBlock2D(in_ch, out_ch, kernel_size=(1, 2), stride=(1, 2), padding=(0,0))                          \n",
    "            in_ch        = out_ch \n",
    "            \n",
    "            self.dec_blocks.append(dec_block) \n",
    "                          \n",
    "    def forward(self, x, encoder_features, t_emb, c_emb, attn_mask=None, key_padding_mask=None): \n",
    "        for i,(dec_block, ftr) in enumerate(zip(self.dec_blocks, encoder_features)):         \n",
    "            x = dec_block.up(x)\n",
    "            x = torch.cat([x, ftr / (2.0**0.5)], dim=1)\n",
    "            \n",
    "            x = dec_block(x, t_emb, c_emb, attn_mask[i], key_padding_mask[i])                                \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9eb6a7-f28f-49a1-9886-adc250f0c858",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fb46a4-b68a-4c9e-b108-0e4ebc7ce4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class QC_Cond_UNet_config:  \n",
    "    model_features: list[int]\n",
    "    clr_dim: int\n",
    "    num_clrs: int\n",
    "    t_emb_size: int  \n",
    "    cond_emb_size: int\n",
    "    num_heads: list[int]\n",
    "    num_res_blocks: list[int]\n",
    "    transformer_depths: list[int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fbf410-04fe-4ec6-b81a-e24586fd2b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class QC_Cond_UNet(Config_Model):\n",
    "    \"\"\"Conditional U-Net model for quantum circuits. Implemets `embedd_clrs` and `invert_clr` functions to embed and decode color-tensors.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_features=[32,32,64], clr_dim=8, num_clrs=8, t_emb_size=128, cond_emb_size=512, \n",
    "                 num_heads=[8,8,2], num_res_blocks=[2, 2, 4], transformer_depths=[1,2,1]):\n",
    "        \n",
    "        super().__init__()       \n",
    "        \n",
    "        self.clr_dim  = clr_dim     \n",
    "        self.num_clrs = num_clrs\n",
    "        \n",
    "        self.t_emb_size    = model_features[0] * 4 if not t_emb_size else t_emb_size\n",
    "        self.cond_emb_size = model_features[0] * 4 if not cond_emb_size else cond_emb_size\n",
    "            \n",
    "        self.params_config = QC_Cond_UNet_config(model_features, self.clr_dim, self.num_clrs, self.t_emb_size, self.cond_emb_size, num_heads, num_res_blocks, transformer_depths)\n",
    "            \n",
    "        #-----------    \n",
    "                             \n",
    "        self.enc_chs = [model_features[0]] + list(model_features)\n",
    "        self.dec_chs = list(model_features)[::-1]\n",
    "        \n",
    "        #-----------\n",
    "                \n",
    "        self.t_emb   = layers.TimeEmbedding(d_model=self.t_emb_size)\n",
    "        self.emb_clr = nn.Embedding(num_embeddings=self.num_clrs, embedding_dim=self.clr_dim)           \n",
    "        \n",
    "        self.conv_in = nn.Conv2d(self.clr_dim, model_features[0], kernel_size=1, stride=1, padding =\"same\") #was kernel_size=3\n",
    "        self.pos_enc = layers.PositionalEncoding2D(d_model=model_features[0])\n",
    "\n",
    "        self.encoder = Encoder(self.enc_chs, self.t_emb_size, cond_emb_size=self.cond_emb_size, num_heads=num_heads, num_res_blocks=num_res_blocks, transformer_depths=transformer_depths)\n",
    "        self.decoder = Decoder(self.dec_chs, self.t_emb_size, cond_emb_size=self.cond_emb_size, num_heads=num_heads[::-1], num_res_blocks=num_res_blocks[::-1], transformer_depths=transformer_depths[::-1])\n",
    "        self.head    = nn.Conv2d(self.dec_chs[-1], self.clr_dim, kernel_size=1, stride=1, padding =\"same\")\n",
    "                                               \n",
    "        self._init_weights()\n",
    "          \n",
    "    def _init_weights(self):\n",
    "        self.emb_clr.weight.requires_grad = False\n",
    "        nn.init.orthogonal_(self.emb_clr.weight.data)\n",
    "        \n",
    "        for enc_block in self.encoder.enc_blocks:\n",
    "            nn.init.orthogonal_(enc_block.down.conv1.weight)\n",
    "        \n",
    "        for dec_block in self.decoder.dec_blocks:\n",
    "            nn.init.orthogonal_(dec_block.up.conv1.weight)\n",
    "        \n",
    "        self.head.weight.data.zero_()\n",
    "       \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    def embedd_clrs(self, x):\n",
    "        sign = torch.sign(x + 0.1)  #trick: add 0.1 so that the sign of 0 is +1, else the 0 token would be all 0s.     \n",
    "        clr  = self.emb_clr(torch.abs(x))      \n",
    "        x = clr * sign[:, :, :, None]        \n",
    "        x = torch.permute(x, (0, 3, 1, 2))       \n",
    "        return x\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def invert_clr(self, x):\n",
    "        #collaps clr to gate ... use cos sim\n",
    "        \n",
    "        clrs = self.emb_clr.weight.detach() # is [clr_num, clr_dim]\n",
    "        \n",
    "        model_device = clrs.device\n",
    "        input_device = x.device\n",
    "        \n",
    "        # to shape [b*space*time, clr_dim]\n",
    "        x      = x.to(model_device)\n",
    "        x_flat = x.permute(0, 2, 3, 1).reshape(-1, x.shape[1])\n",
    "                         \n",
    "        #normlize for cos sim       \n",
    "        norm_clr    = clrs   / torch.linalg.vector_norm(  clrs, dim=1, keepdim=True) \n",
    "        norm_x_flat = x_flat / torch.linalg.vector_norm(x_flat, dim=1, keepdim=True) \n",
    "        \n",
    "        #matmul out is [clr_num, b*space*time]\n",
    "        sim = torch.matmul(norm_clr, norm_x_flat.T) \n",
    "            \n",
    "        #get highest abs(similarity) and sign of it\n",
    "        abs_sim = sim.abs()\n",
    "        max_idx = torch.argmax(abs_sim, dim=0) #reduce the clr_num dim\n",
    "        sign = torch.sign(sim[max_idx, torch.arange(x_flat.shape[0])])\n",
    "        scores_flat = max_idx * sign\n",
    "\n",
    "        # back to [b, space, time]\n",
    "        scores = scores_flat.reshape(x.shape[0], x.shape[2], x.shape[3]).to(torch.int64)      \n",
    "        scores = scores.to(input_device)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    def forward(self, x, t, c_emb, attn_mask=None, key_padding_mask=None):\n",
    "        if attn_mask        is None: attn_mask        = [None] * len(self.enc_chs)\n",
    "        if key_padding_mask is None: key_padding_mask = [None] * len(self.enc_chs)\n",
    "              \n",
    "        t_emb = self.t_emb(t)\n",
    "                \n",
    "        x = self.conv_in(x)            \n",
    "        x = self.pos_enc(x) \n",
    "        \n",
    "        enc_ftrs = self.encoder(x, t_emb=t_emb, c_emb=c_emb, attn_mask=attn_mask, key_padding_mask=key_padding_mask)[::-1]\n",
    "        out      = self.decoder(x=enc_ftrs[0], encoder_features=enc_ftrs[1:], t_emb=t_emb, c_emb=c_emb, \n",
    "                                attn_mask=attn_mask[::-1][1:], key_padding_mask=key_padding_mask[::-1][1:])\n",
    "        out      = self.head(out)       \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5659ff8-40e4-4ea4-a02a-9b0e42f99a81",
   "metadata": {},
   "source": [
    "## Unitary compilation extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa89a58-ac22-4cf8-8311-a2f5dacd3702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class QC_Compilation_UNet_config(QC_Cond_UNet_config):  \n",
    "    unitary_encoder_config: Unitary_encoder_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313ba1a-bedf-4622-8af9-8ba76b992ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class QC_Compilation_UNet(QC_Cond_UNet):\n",
    "    \"\"\"Extension of the `QC_Cond_UNet` to accept unitary conditions.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_features=[32,32,64], clr_dim=8, num_clrs=8, t_emb_size=128, cond_emb_size=512, \n",
    "                 num_heads=[8,8,2], num_res_blocks=[2, 2, 4], transformer_depths=[1,2,1], unitary_encoder_config=None): \n",
    "        \n",
    "        super().__init__(model_features, clr_dim, num_clrs, t_emb_size, cond_emb_size, num_heads, num_res_blocks, transformer_depths)\n",
    "\n",
    "        if is_dataclass(unitary_encoder_config):\n",
    "            unitary_encoder_config = asdict(unitary_encoder_config)\n",
    "        self.unitary_encoder = Unitary_encoder(**unitary_encoder_config)\n",
    "        self.params_config   = QC_Compilation_UNet_config(model_features, self.clr_dim, self.num_clrs, self.t_emb_size, self.cond_emb_size, num_heads, num_res_blocks, transformer_depths, self.unitary_encoder.params_config)\n",
    "    \n",
    "    def forward(self, x, t, c_emb, U, attn_mask=None, key_padding_mask=None):\n",
    "        u_emb = self.unitary_encoder(U)            # [batch, seq2, ch]     \n",
    "        c_emb = torch.cat([c_emb, u_emb], dim=1)   # [batch, seq1+seq2, ch]  \n",
    "        out = super().forward(x, t, c_emb, attn_mask, key_padding_mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfd7536-56f8-479d-911f-3d62b427ecba",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f41df-ba6d-429d-a6a2-a9ff60a1ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
