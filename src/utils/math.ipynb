{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ea1626-1c62-43c5-b4c1-0267268179d2",
   "metadata": {},
   "source": [
    "# Math and algorithms\n",
    "\n",
    "> Miscellaneous math and algorithm code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7b3562-52ab-457f-80be-a9fb1801d31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils.math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983ccb27-8049-48ad-97e1-c1763fbb71e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from genQC.imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea057fd-ba30-4fda-9d19-a1c44d0d5d15",
   "metadata": {},
   "source": [
    "## Matrix functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf98023-d46f-46da-8342-c73e8b08d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def matrix_power(x: torch.Tensor, p: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Power of a matrix using Eigenspace Decomposition. Assuming decomposition of `x` exists.\n",
    "    \"\"\"\n",
    "    \n",
    "    vals, vecs = torch.linalg.eig(x)\n",
    "    vals_pow   = torch.pow(vals, p)\n",
    "    matrix_pow = torch.matmul(vecs, torch.matmul(torch.diag(vals_pow), torch.inverse(vecs)))\n",
    "    \n",
    "    return matrix_pow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77969d8-4d00-472e-bd2f-f75751da1f42",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35135abe-a5d2-476d-92fc-e9e1bbe300de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def gram_schmidt(X: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Perform Gramâ€“Schmidt orthonormalization on the vectors given by the rows of matrix X.\n",
    "    \"\"\"\n",
    "    assert X.dim() == 2, \"Only 2-dim tensor supported.\"\n",
    "    \n",
    "    X_type = X.dtype\n",
    "    X      = X.to(torch.float64)    \n",
    "    Q = []\n",
    "    for q in X:\n",
    "        # Take the current row vector \n",
    "        # Subtract projec+tions onto existing basis vectors\n",
    "        for v in Q:\n",
    "            q = q - torch.dot(q, v) * v\n",
    "        # Normalize the vector\n",
    "        q = q / torch.norm(q)\n",
    "        Q.append(q)\n",
    "    return torch.stack(Q).to(X_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f2242-a888-470f-831e-977c78959524",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a0e934-0bf3-48dd-b706-ab1d3a87b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
