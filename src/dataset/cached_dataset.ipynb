{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8980c24-d62e-462b-ba89-3195cfdcc374",
   "metadata": {},
   "source": [
    "# Cached dataset\n",
    "\n",
    "> Classes to create a dataset with cached labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8832bdd-f61c-44e1-8619-a9cb352ba768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dataset.cached_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06272f6f-b4e3-4504-a90a-feebbf6ad821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from genQC.imports import *\n",
    "from genQC.dataset.config_dataset import ConfigDataset, ConfigDatasetConfig\n",
    "from genQC.utils.config_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8e640e-c614-4d52-b772-c173b2682ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class CachedOpenCLIPDatasetConfig(ConfigDatasetConfig):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119077c9-999b-44f7-8099-79037503d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CachedOpenCLIPDataset(ConfigDataset):\n",
    "    \"\"\"\n",
    "    Adds `.caching` to the `ConfigDataset` class.\n",
    "    \n",
    "    Cached dataset that caches the label `y` prompts using the CLIP `text_encoder`. This speeds up training significantly.\n",
    "    \"\"\"\n",
    "\n",
    "    #-----------------------------------\n",
    "    \n",
    "    def x_y_preprocess(self, balance_max, shuffle=False, max_samples=None, make_unique=True):\n",
    "        x_proc, y_proc, *z = super().x_y_preprocess(balance_max=balance_max, shuffle=shuffle, max_samples=max_samples, make_unique=make_unique)        \n",
    "        y_proc = self.caching(y_proc)\n",
    "        return x_proc, y_proc, *z\n",
    "    \n",
    "    def caching(self, y_proc, y_on_cpu=False):\n",
    "        print(\"[INFO]: Generate cache: converting tensors to str and tokenize\")   \n",
    "        \n",
    "        print(\" - to str list\")  \n",
    "        if isinstance(y_proc, (torch.Tensor, torch.IntTensor, torch.FloatTensor, torch.LongTensor)):         \n",
    "            y_str = [str(i) for i in y_proc.cpu().tolist()]\n",
    "        elif isinstance(y_proc, list): \n",
    "            y_str = []\n",
    "            for iy in y_proc:                \n",
    "                if isinstance(iy, np.ndarray): y_str += [str(i) for i in iy.tolist()]        # list of numpy arrays\n",
    "                else:                          y_str += [str(i) for i in iy.cpu().tolist()]  # list of tensors\n",
    "        elif isinstance(y_proc, np.ndarray):\n",
    "            y_str = [str(i) for i in y_proc.tolist()]\n",
    "            \n",
    "        else: raise NotImplementedError()\n",
    "                            \n",
    "        print(\" - tokenize_and_push_to_device\")  \n",
    "        y_tok = self.text_encoder.tokenize_and_push_to_device(y_str, to_device= not y_on_cpu)\n",
    "        if y_on_cpu: y_tok = y_tok.cpu()\n",
    "        \n",
    "        \n",
    "        # Now for using cache we need the uniques and the corresponding indices of the uniques\n",
    "        y_uniques, y_ptrs  = torch.unique(torch.cat([self.text_encoder.empty_token.to(y_tok.device), y_tok], dim=0), dim=0, return_inverse=True)\n",
    "    \n",
    "        cached_empty_token_index = y_ptrs[0]  #store what index the empty token has   \n",
    "        y_ptrs                   = y_ptrs[1:] #remove the cat empty token\n",
    "      \n",
    "        # Use cache\n",
    "        print(\" - generate_cache\")  \n",
    "        self.text_encoder.generate_cache(tokens=y_uniques, cached_empty_token_index=cached_empty_token_index, y_on_cpu=y_on_cpu)\n",
    "      \n",
    "        print(f\"[INFO]: Generated cache, {y_ptrs.shape=}\")  \n",
    "        return y_ptrs.clone()\n",
    "    \n",
    "    #-------------------------------------------\n",
    "    \n",
    "    def get_dataloaders(self, batch_size, text_encoder, p_valid=0.1, balance_max=None, max_samples=None):\n",
    "        self.text_encoder = text_encoder    \n",
    "        return super().get_dataloaders(batch_size, p_valid, balance_max, max_samples)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f26a8-ac40-4e91-8c0e-1ef07a0fd4f4",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0474216-8e0c-4ba7-9a37-571ac7d8e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
