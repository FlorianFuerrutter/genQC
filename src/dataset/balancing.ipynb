{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8980c24-d62e-462b-ba89-3195cfdcc374",
   "metadata": {},
   "source": [
    "# Dataset balancing\n",
    "\n",
    "> Helper functions used to balance a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8832bdd-f61c-44e1-8619-a9cb352ba768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dataset.balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06272f6f-b4e3-4504-a90a-feebbf6ad821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from genQC.imports import *\n",
    "import genQC.dataset.dataset_helper as dahe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132df6f-d099-40e0-95a8-9d735211b2dc",
   "metadata": {},
   "source": [
    "## Qircuit length balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ce23e-30fc-434f-9443-3cf97f507b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_tensor_gate_length(clr_tensor: torch.Tensor, padding_token: int = 0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Returns the gate count of a tokenized circuit.\n",
    "    Make sure you use use the correct `padding_token`.\n",
    "    \n",
    "    \"\"\"\n",
    "    assert clr_tensor.dim() == 3, \"[b, s, t]\"\n",
    "    \n",
    "    red_clr_tensor = (clr_tensor != padding_token).any(dim=1) # [b, t]\n",
    "    return torch.count_nonzero(red_clr_tensor, dim=1)         # [b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36032308-bd0e-4409-9db0-9d89fc258e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def add_balance_fn_quantile_qc_length(indices: Union[np.ndarray, torch.Tensor], \n",
    "                                      x: Union[np.ndarray, torch.Tensor], \n",
    "                                      y: Union[np.ndarray, torch.Tensor], \n",
    "                                      *z, \n",
    "                                      padding_token: int = 0,\n",
    "                                      balance_quantile: float = 0.5,\n",
    "                                      device: torch.device = torch.device(\"cpu\"),\n",
    "                                      quantile_length_weights: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None) -> torch.Tensor:\n",
    "    \"\"\"Balances according to gate length.\"\"\"\n",
    "    \n",
    "    xb = x[indices].to(device)\n",
    "    l  = get_tensor_gate_length(xb, padding_token=padding_token).to(device)\n",
    "    \n",
    "    l_uniques, l_uniques_cnt = torch.unique(l, dim=0, return_counts=True)\n",
    "\n",
    "    #-----------------------------------\n",
    "    # samples = torch.min(l_uniques_cnt)\n",
    "    # samples = torch.median(l_uniques_cnt)\n",
    "    samples = torch.quantile(l_uniques_cnt.float(), balance_quantile, interpolation='nearest', dim=0).to(l_uniques_cnt.dtype)\n",
    "    samples = max(samples, 2)\n",
    "\n",
    "    #-----------------------------------\n",
    "    sub_ind = list()   \n",
    "    for l_unique in l_uniques.to(device):      \n",
    "        comp = (l==l_unique)\n",
    "        ind  = comp.nonzero().squeeze().cpu()\n",
    "        \n",
    "        if ind.dim() > 0:\n",
    "            if exists(quantile_length_weights):\n",
    "                _samples = int(quantile_length_weights(l_unique, samples))\n",
    "            else:\n",
    "                _samples = samples\n",
    "            \n",
    "            ind = dahe.shuffle_tensor_dataset(ind) \n",
    "            ind = ind[:_samples]\n",
    "        else:\n",
    "            ind = ind[None]\n",
    "        \n",
    "        sub_ind.append(ind)\n",
    "\n",
    "    sub_ind = torch.cat(sub_ind, dim=0)\n",
    "      \n",
    "    indices = indices[sub_ind]\n",
    "    \n",
    "    if indices.ndim < 1:  \n",
    "        indices = indices[None]\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f26a8-ac40-4e91-8c0e-1ef07a0fd4f4",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0474216-8e0c-4ba7-9a37-571ac7d8e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
