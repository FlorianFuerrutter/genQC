{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8980c24-d62e-462b-ba89-3195cfdcc374",
   "metadata": {},
   "source": [
    "# Quantum circuit dataset\n",
    "\n",
    "> Dataset for quantum circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8832bdd-f61c-44e1-8619-a9cb352ba768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dataset.circuits_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06272f6f-b4e3-4504-a90a-feebbf6ad821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from genQC.imports import *\n",
    "from genQC.dataset.cached_dataset import CachedOpenCLIPDataset, CachedOpenCLIPDatasetConfig\n",
    "from genQC.dataset.mixed_cached_dataset import MixedCachedOpenCLIPDataset, MixedCachedOpenCLIPDatasetConfig\n",
    "from genQC.utils.config_loader import *\n",
    "from genQC.dataset.config_dataset import ConfigDataset\n",
    "from genQC.dataset.dataset_helper import shuffle_tensor_dataset\n",
    "from genQC.utils.misc_utils import MemoryCleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93281557-359a-4b89-906d-36ebfc72bf98",
   "metadata": {},
   "source": [
    "## Simple Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016fc327-f986-4d69-b5f0-1b39466fb528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class CircuitsConfigDatasetConfig(CachedOpenCLIPDatasetConfig):\n",
    "    optimized: bool\n",
    "    random_samples: int  \n",
    "    num_of_qubits: int  \n",
    "    min_gates: int \n",
    "    max_gates: int \n",
    "    max_params: int\n",
    "    gate_pool: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36032308-bd0e-4409-9db0-9d89fc258e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CircuitsConfigDataset(CachedOpenCLIPDataset):\n",
    "    \"\"\"Dataset for quantum circuits, access `gate_pool` directly and all other paras with `.params_config`\"\"\"\n",
    "    \n",
    "    req_params = [f.name for f in dataclasses.fields(CircuitsConfigDatasetConfig)]\n",
    "\n",
    "    #-----------------------------------\n",
    "    def __init__(self, device: torch.device=torch.device(\"cpu\"), **parameters) -> None:\n",
    "        super().__init__(device, **parameters)        \n",
    "\n",
    "        \n",
    "        if isinstance(list(parameters[\"gate_pool\"])[0], str):\n",
    "            self.gate_pool = list(parameters[\"gate_pool\"])\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                self.gate_pool = [get_obj_from_str(node) for node in parameters[\"gate_pool\"]]   \n",
    "            except Exception as er:\n",
    "                print(f\"[WARNING]: error => {er}\")\n",
    "                print(f\"[WARNING]: gate_pool is passed as str\")\n",
    "                self.gate_pool = [str(node) for node in parameters[\"gate_pool\"]]   \n",
    "    \n",
    "    @property\n",
    "    def params_config(self):\n",
    "        params_config = super().params_config         \n",
    "        \n",
    "        if type(self) == CircuitsConfigDataset:\n",
    "            params_config = CircuitsConfigDatasetConfig(**params_config)\n",
    "        return params_config   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6322ed9-c703-41df-88a3-6b163c051af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': '__main__.CircuitsConfigDataset',\n",
       " 'device': 'cpu',\n",
       " 'comment': '',\n",
       " 'save_path': None,\n",
       " 'save_datetime': '06/01/2025 11:31:35',\n",
       " 'save_type': 'safetensors',\n",
       " 'params': CircuitsConfigDatasetConfig(store_dict={'x': 'tensor', 'y': 'tensor_list'}, dataset_to_gpu=None, optimized=None, random_samples=None, num_of_qubits=None, min_gates=None, max_gates=None, max_params=None, gate_pool=['qiskit.circuit.library.standard_gates.h.HGate', 'qiskit.circuit.library.standard_gates.x.CXGate'])}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = {k:None for k in CircuitsConfigDataset.req_params}\n",
    "init[\"gate_pool\"]  = [\"qiskit.circuit.library.standard_gates.h.HGate\",\n",
    "                      \"qiskit.circuit.library.standard_gates.x.CXGate\"]\n",
    "init[\"store_dict\"] = {\"x\":\"tensor\", \"y\":\"tensor_list\"}\n",
    "\n",
    "a = CircuitsConfigDataset(**init)\n",
    "a.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85fedcd-5a95-4466-956f-055d887fe773",
   "metadata": {},
   "source": [
    "## Mixed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9a200-f9eb-42f9-b3c3-e074e377737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class MixedCircuitsConfigDatasetConfig(CircuitsConfigDatasetConfig, MixedCachedOpenCLIPDatasetConfig):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e804a8d7-dcf3-40e4-83a5-cd98207c8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MixedCircuitsConfigDataset(CircuitsConfigDataset, MixedCachedOpenCLIPDataset):\n",
    "    \"\"\"\n",
    "    Dataset that uses multiple cached dataset and combines them with padding, either i) Bucket or ii) Max.\n",
    "    Also provides a corresponding `collate_fn` for training.\n",
    "    \"\"\"\n",
    "\n",
    "    req_params = [f.name for f in dataclasses.fields(MixedCircuitsConfigDatasetConfig)]\n",
    "\n",
    "    #-----------------------------------\n",
    "    \n",
    "    @property\n",
    "    def params_config(self):\n",
    "        params_config = super().params_config            \n",
    "        if type(self) == MixedCircuitsConfigDataset:\n",
    "            params_config = MixedCircuitsConfigDatasetConfig(**params_config)\n",
    "        return params_config   \n",
    "\n",
    "    #-----------------------------------\n",
    "\n",
    "    def _get_cut_sizes(self, z):\n",
    "        z_0 = torch.max(z[:, 0]) # space\n",
    "        z_1 = torch.max(z[:, 1]) # time\n",
    "        z_1 = (torch.ceil(z_1 / self.model_scale_factor) * self.model_scale_factor).to(torch.int32)\n",
    "        return z_0, z_1\n",
    "  \n",
    "    def _cut(self, x, y, z):     \n",
    "        z_0, z_1 = self._get_cut_sizes(z)\n",
    "        \n",
    "        x = x[:, :z_0, :z_1] # cut down to max [b, bits, time] of batch\n",
    "        return x, y\n",
    "    \n",
    "    def _cut_compilation_params(self, x, y, p, U, z):  \n",
    "        z_0, z_1 = self._get_cut_sizes(z)\n",
    "        bit_exp  = 2**z_0\n",
    "        \n",
    "        x = x[:, :z_0, :z_1]              # cut down to max [b, bits, time] of batch\n",
    "        p = p[:,    :, :z_1]              # cut down to max [b, nP  , time] of batch       \n",
    "        U = U[:, :, :bit_exp, :bit_exp]   # [b, Re/Im, 2^n, 2^n]\n",
    "        return x, y, p, U\n",
    "    \n",
    "    #-----------------------------------\n",
    "    # BUCKET PADDING, all x,y are already passed as batch\n",
    "        \n",
    "    def cut_padding_Bucket_collate_fn(self, b):     \n",
    "        \"\"\"this function is called for training for every batch, order in b is store dict\"\"\"       \n",
    "\n",
    "        x, y, z = b[0]\n",
    "        x, y = self._cut(x, y, z)\n",
    "        return x, y \n",
    "\n",
    "        \n",
    "    def cut_padding_Bucket_collate_fn_compilation(self, b):     \n",
    "        \"\"\"this function is called for training for every batch\"\"\"    \n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "    def cut_padding_Bucket_collate_fn_compilation_params(self, b):     \n",
    "        \"\"\"this function is called for training for every batch, order in b is store dict\"\"\"    \n",
    "        \n",
    "        b = b[0] # {'x': 'tensor', 'y': 'numpy', 'params': 'tensor', 'U': 'tensor', 'z': 'tensor'}\n",
    "        \n",
    "        x = b[0]\n",
    "        y = b[1]  \n",
    "        p = b[2]\n",
    "        U = b[3]\n",
    "        z = b[4]\n",
    "        \n",
    "        #---------------\n",
    "        \n",
    "        x, y, p, U = self._cut_compilation_params(x, y, p, U, z)\n",
    "               \n",
    "        return x, y, p, U\n",
    "    \n",
    "    #-----------------------------------\n",
    "    # MAX PADDING, x are passes as sampled list (batch), std collate them\n",
    "    \n",
    "    def cut_padding_collate_fn(self, b):     \n",
    "        \"\"\"this function is called for training for every batch\"\"\"    \n",
    "        x, y, z = torch.utils.data.default_collate(b)\n",
    "        x, y    = self._cut(x, y, z)\n",
    "        return x, y \n",
    "\n",
    "    def cut_padding_collate_fn_compilation(self, b):\n",
    "        \"\"\"this function is called for training for every batch\"\"\"    \n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def cut_padding_collate_fn_compilation_params(self, b):\n",
    "        \"\"\"this function is called for training for every batch, order in b is store dict\"\"\"    \n",
    "        # {'x': 'tensor', 'y': 'numpy', 'params': 'tensor', 'U': 'tensor', 'z': 'tensor'}\n",
    "        x, y, p, U, z = torch.utils.data.default_collate(b)\n",
    "        x, y, p, U    = self._cut_compilation_params(x, y, p, U, z)        \n",
    "        return x, y, p, U   \n",
    "        \n",
    "    #-----------------------------------\n",
    "    \n",
    "    @staticmethod\n",
    "    def _preprocess_dataset(dataset, device, balance_max, max_samples, i, shuffle, make_unique, pad_constant, \n",
    "                            model_scale_factor, parameters, max_gates, max_qubits):\n",
    "\n",
    "        dataset = dataset.to(device)\n",
    "\n",
    "        existing_z_type = dataset.store_dict.pop(\"z\", None)  # remove z, as it would mess up `ConfigDataset.x_y_preprocess`, it would be put in `*c`.\n",
    "        if exists(existing_z_type):\n",
    "            assert existing_z_type == \"tensor\"\n",
    "            z = dataset.z\n",
    "        else:\n",
    "            z = None\n",
    "        \n",
    "        x, y, *c = ConfigDataset.x_y_preprocess(dataset, balance_max=balance_max, max_samples=max_samples[i], shuffle=shuffle, make_unique=make_unique)       \n",
    "        x = x.to(device)    # [b, s, t]   \n",
    "        \n",
    "        print(f\" - dataset size after balancing {x.shape[0]}\")\n",
    "\n",
    "        #-------\n",
    "        # store original size\n",
    "        if not_exists(z):\n",
    "            z = torch.zeros((x.shape[0], 2), device=device, dtype=torch.int32)\n",
    "            z[:, 0] = max(dataset.params_config.num_of_qubits, 1)\n",
    "            \n",
    "            red_x   = torch.sum(x.abs(), dim=1)          # [b, t]   .. collaps the zeros to get circuit length\n",
    "            z[:, 1] = torch.count_nonzero(red_x, dim=1)  # [b]         \n",
    "            z[z[:, 1]==0, 1] = 1            \n",
    "\n",
    "        # Create masks for space and time padding\n",
    "        space_mask = torch.arange(x.shape[1], device=x.device).unsqueeze(0) >= z[:, 0].unsqueeze(1)\n",
    "        time_mask  = torch.arange(x.shape[2], device=x.device).unsqueeze(0) >= z[:, 1].unsqueeze(1)\n",
    "\n",
    "        # Apply masks to pad_constant to handle both dimensions\n",
    "        x = torch.where(space_mask.unsqueeze(2), pad_constant, x)\n",
    "        x = torch.where( time_mask.unsqueeze(1), pad_constant, x)\n",
    "        \n",
    "        z[:, 1] = (torch.ceil(z[:, 1] / model_scale_factor) * model_scale_factor).to(torch.int32) #for cut needs multiple\n",
    "\n",
    "        #-------\n",
    "        \n",
    "        # now pad x, padding is defined from last dim forward!        \n",
    "        pad = (0, max_gates-dataset.params_config.max_gates, 0, max_qubits-dataset.params_config.num_of_qubits) \n",
    "        x   = F.pad(x, pad, \"constant\", pad_constant)\n",
    "        \n",
    "        #-------\n",
    "\n",
    "        c = MixedCachedOpenCLIPDataset._add_missing_conditions(parameters, dataset, c, x.shape[0], \"cpu\")\n",
    "\n",
    "        dataset = dataset.to(\"cpu\") #helps with gpu mem overflowing\n",
    "        del dataset\n",
    "            \n",
    "        return x.cpu(), y, z.cpu(), *[ic.cpu() for ic in c]\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_datasets(datasets: list[CircuitsConfigDataset], balance_maxes: list, pad_constant, device: torch.device=torch.device(\"cpu\"), bucket_batch_size=None, \n",
    "                      max_samples=None, shuffle=True, make_unique=True, test_split=0.05, pad_with_memmap=False, **parameters):\n",
    "        if pad_constant == 0:\n",
    "            print(\"[WARNING]: >pad_constant == 0<; This could be an error!\")\n",
    "        \n",
    "        model_scale_factor = parameters[\"model_scale_factor\"]\n",
    "        \n",
    "        max_qubits  = max(dataset.params_config.num_of_qubits for dataset in datasets)\n",
    "        max_gates   = max(dataset.params_config.max_gates     for dataset in datasets)\n",
    "        max_gates   = int(np.ceil(max_gates /model_scale_factor) * model_scale_factor)\n",
    "        max_params  = max(dataset.params_config.max_params for dataset in datasets)\n",
    "        \n",
    "        parameters[\"num_of_qubits\"]     = max_qubits\n",
    "        parameters[\"max_gates\"]         = max_gates\n",
    "        parameters[\"max_params\"]        = max_params\n",
    "        parameters[\"random_samples\"]    = sum([dataset.params_config.random_samples for dataset in datasets])\n",
    "        parameters[\"min_gates\"]         = min([dataset.params_config.min_gates      for dataset in datasets])\n",
    "        parameters[\"comment\"]           = f\"Generated with 'from_datasets' with {len(datasets)} datasets. Qubits: {[dataset.params_config.num_of_qubits for dataset in datasets]}.\"\n",
    "        parameters[\"pad_constant\"]      = pad_constant\n",
    "        parameters[\"bucket_batch_size\"] = bucket_batch_size\n",
    "         \n",
    "        parameters[\"store_dict\"] = {}\n",
    "        for dataset in datasets:\n",
    "            parameters[\"store_dict\"] |= dataset.params_config.store_dict   #needs python 3.9 for union of dict  \n",
    "        parameters[\"store_dict\"][\"z\"]   = \"tensor\" #add special item\n",
    "\n",
    "        #-----------------\n",
    "        \n",
    "        xs, ys, zs, cs = MixedCircuitsConfigDataset._preprocess_datasets(datasets, device, balance_maxes, max_samples, shuffle, make_unique, pad_constant, \n",
    "                                                                         model_scale_factor, parameters, max_gates=max_gates, max_qubits=max_qubits)            \n",
    "        #-----------------\n",
    "\n",
    "        has_U = \"U\" in parameters[\"store_dict\"]\n",
    "        has_p = \"params\" in parameters[\"store_dict\"]\n",
    "        \n",
    "        if bucket_batch_size > 0:\n",
    "            collate_fn_name = MixedCircuitsConfigDataset.cut_padding_Bucket_collate_fn.__name__\n",
    "            if has_U: \n",
    "                collate_fn_name = MixedCircuitsConfigDataset.cut_padding_Bucket_collate_fn_compilation.__name__\n",
    "                if has_p: \n",
    "                    collate_fn_name = MixedCircuitsConfigDataset.cut_padding_Bucket_collate_fn_compilation_params.__name__\n",
    "        \n",
    "        else:\n",
    "            collate_fn_name = MixedCircuitsConfigDataset.cut_padding_collate_fn.__name__   \n",
    "            if has_U: \n",
    "                collate_fn_name = MixedCircuitsConfigDataset.cut_padding_collate_fn_compilation.__name__\n",
    "                if has_p: \n",
    "                    collate_fn_name = MixedCircuitsConfigDataset.cut_padding_collate_fn_compilation_params.__name__\n",
    "\n",
    "        parameters[\"collate_fn\"] = collate_fn_name\n",
    "        \n",
    "        #-----------------\n",
    "        if bucket_batch_size > 0:\n",
    "            xs, ys, zs, cs = MixedCachedOpenCLIPDataset._reorder_to_buckets(parameters, bucket_batch_size, xs, ys, zs, cs)\n",
    "                                     \n",
    "        x = torch.cat(xs)\n",
    "        y = ys                 # torch.cat(ys) is wrong,  y is list of numpy or str!! not a tensor\n",
    " \n",
    "        if isinstance(y, list): \n",
    "            match parameters[\"store_dict\"][\"y\"]:\n",
    "                case \"numpy\":  y = np.concatenate(y, axis=0)\n",
    "                case \"tensor\": y = torch.cat(y, dim=0)\n",
    "                case _: raise NotImplementedError()\n",
    "            \n",
    "        z = torch.cat(zs)\n",
    "        c = cs\n",
    "        \n",
    "        #-----------------\n",
    "\n",
    "        params_pad  = (max_params, max_gates)\n",
    "        unitary_pad = 2**max_qubits\n",
    "        \n",
    "        ci_list, ci_k_list, memmap_cleans = MixedCachedOpenCLIPDataset._pad_conditions(parameters, bucket_batch_size, c, unitary_pad=unitary_pad, params_pad=params_pad, pad_with_memmap=pad_with_memmap)\n",
    "        \n",
    "        #-----------------    \n",
    "\n",
    "        mixed_CircuitsConfigDataset, mixed_CircuitsConfigDataset_test = \\\n",
    "                MixedCircuitsConfigDataset._create_train_valid_datasets(device, parameters, test_split, x, y, z, ci_list, ci_k_list, shuffle=shuffle)\n",
    "\n",
    "        if pad_with_memmap:\n",
    "            mixed_CircuitsConfigDataset.memmap_cleans      = memmap_cleans\n",
    "            mixed_CircuitsConfigDataset_test.memmap_cleans = memmap_cleans\n",
    "        \n",
    "        return mixed_CircuitsConfigDataset, mixed_CircuitsConfigDataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f26a8-ac40-4e91-8c0e-1ef07a0fd4f4",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0474216-8e0c-4ba7-9a37-571ac7d8e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
