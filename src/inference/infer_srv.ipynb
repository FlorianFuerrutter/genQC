{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8980c24-d62e-462b-ba89-3195cfdcc374",
   "metadata": {},
   "source": [
    "# Inference SRV functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8832bdd-f61c-44e1-8619-a9cb352ba768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp inference.infer_srv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06272f6f-b4e3-4504-a90a-feebbf6ad821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from genQC.imports import *\n",
    "from genQC.inference.infer_misc import *\n",
    "from genQC.inference.infer_gate_hist import get_circuit_gate_length\n",
    "from genQC.platform.qcircuit_util import get_entanglement_bins\n",
    "from genQC.platform.simulation.qcircuit_sim import schmidt_rank_vector\n",
    "from genQC.inference.infer_compilation import generate_comp_tensors\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import qiskit.quantum_info as qi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfa411d-6574-4e83-875b-40c146b4a8e3",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45069ca8-b558-413d-9848-934d631b674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_all_srvs(num_of_qubits):\n",
    "    srvs = [x for x in itertools.product(*([[1,2]]*num_of_qubits))]\n",
    "    srvs = np.array(srvs, dtype=int)[np.sum(srvs, axis=1)!=num_of_qubits+1].tolist()\n",
    "    srvs = sorted(srvs, key=lambda x: sum(x))\n",
    "    return srvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868fe792-0d99-46e6-ac15-4c2a6e7ef640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_srv_tensors(pipeline, prompt, samples, system_size, num_of_qubits, max_gates, g, no_bar=True, unique=False, auto_batch_size=512):\n",
    "    if samples==0:\n",
    "        out_tensor = torch.zeros((0, system_size, max_gates))\n",
    "        return out_tensor\n",
    "    \n",
    "    #----------------------\n",
    "    #prepare condtions\n",
    "    \n",
    "    prompt = str(prompt)\n",
    "    c = pipeline.text_encoder.tokenize_and_push_to_device(prompt)\n",
    "\n",
    "    #----------------------\n",
    "    #sample and post process to tensor encodings\n",
    "\n",
    "    batch_samples = [auto_batch_size] * int(np.floor(samples/auto_batch_size))\n",
    "    if samples % auto_batch_size > 0: batch_samples.append(samples % auto_batch_size)\n",
    "    if len(batch_samples) == 0: batch_samples.append(samples)\n",
    "\n",
    "    out_tensor_list = []\n",
    "    for batch_sample in batch_samples:     \n",
    "        \n",
    "        c_batch = c.repeat(batch_sample, *[1]*(c.dim()-1))\n",
    "        \n",
    "        latents = torch.randn((c_batch.shape[0], pipeline.model.clr_dim, system_size, max_gates))    \n",
    "        out_tensor = pipeline(latents=latents, c=c_batch, g=g, no_bar=no_bar, enable_guidance=True)   \n",
    "        out_tensor_list.append(out_tensor)\n",
    "        \n",
    "    out_tensor = torch.cat(out_tensor_list)\n",
    "    out_tensor = pipeline.model.invert_clr(out_tensor)\n",
    "    out_tensor = out_tensor[:, :num_of_qubits]\n",
    "    \n",
    "    if unique: out_tensor = torch.unique(out_tensor, dim=0)\n",
    "    \n",
    "    if not no_bar: print(f\"[INFO]: (generate_srv_tensors) Generated {'unique_cnt ' if unique else ''}{out_tensor.shape[0]} tensors\")\n",
    "\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ae8e82-dcc4-456b-8422-cd8ffdd25eab",
   "metadata": {},
   "source": [
    "## Convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7e53f2-c673-40ae-8378-833fd78be0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_tensors_to_srvs(out_tensor, gate_pool, sort_srv=False, place_barrier=False, n_jobs=1): \n",
    "    qc_list, error_cnt = convert_tensors_to_circuits(out_tensor, gate_pool=gate_pool, place_barrier=place_barrier)\n",
    "    \n",
    "    srv_list = []\n",
    "    \n",
    "    #---------------------------------------------\n",
    "    # This is a bottle-neck for more qubits, speed up with async\n",
    "    \n",
    "    if n_jobs > 1:\n",
    "        assert sort_srv == False\n",
    "        \n",
    "        f = lambda qc: schmidt_rank_vector(qi.DensityMatrix(qc))\n",
    "        # srv_list = Parallel(n_jobs=n_jobs, prefer=\"threads\")(delayed(f)(qc) for qc in qc_list)  #prefer=\"threads\"\n",
    "        srv_list = Parallel(n_jobs=n_jobs)(delayed(f)(qc) for qc in qc_list) \n",
    "    \n",
    "    else:  \n",
    "        for qc in qc_list:            \n",
    "            srv = schmidt_rank_vector(qi.DensityMatrix(qc))\n",
    "            \n",
    "            if sort_srv: srv = sorted(srv)      \n",
    "            srv_list.append(srv)  \n",
    "  \n",
    "    return qc_list, error_cnt, srv_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f247332-0894-4603-bbee-c556bc5820b6",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4de23-cdb5-4b00-a89e-04b14cffcf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_srv_accuracy(srv_list, target_srv):\n",
    "    if not isinstance(srv_list  , (torch.Tensor, torch.IntTensor, torch.FloatTensor, torch.LongTensor)):   srv_list = torch.tensor(srv_list)\n",
    "    if not isinstance(target_srv, (torch.Tensor, torch.IntTensor, torch.FloatTensor, torch.LongTensor)): target_srv = torch.tensor(target_srv, device=srv_list.device)\n",
    "    \n",
    "    srv_uniques, srv_uniques_cnt = torch.unique(srv_list, dim=0, return_counts=True)\n",
    "    \n",
    "    if srv_uniques.numel() == 0: return 0\n",
    "\n",
    "    comp  = torch.all(target_srv==srv_uniques, dim=1)\n",
    "    index = comp.nonzero().squeeze() \n",
    "        \n",
    "    if index.dim() == 0: correct_srv_percentage = srv_uniques_cnt[index]/srv_uniques_cnt.sum()           \n",
    "    else:                correct_srv_percentage = 0 \n",
    " \n",
    "    return correct_srv_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8e729d-edf2-4228-af86-4f4449acc61d",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10594109-3085-4c7d-a92b-d7535ab0ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def true_sample_bin_dist(samples_per_bin, bin_size):\n",
    "    true_samples     = [max(samples_per_bin//bin_size, 1) for i in range(bin_size)]\n",
    "\n",
    "    if samples_per_bin-sum(true_samples) > 0:\n",
    "        true_samples[0] += (samples_per_bin-sum(true_samples))\n",
    "    \n",
    "    # assert sum(true_samples)==samples_per_bin\n",
    "    # assert len(true_samples)==bin_size\n",
    "\n",
    "    # print(f\"{true_samples=}\")\n",
    "    \n",
    "    return true_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61603163-81b9-439c-b827-72fe37a21b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def test_srv_clr_distribution_bin_samples(pipeline, samples_per_bin, system_size, num_of_qubits, max_gates, g, gate_pool, silent=False, device=\"cpu\", U=None, prompt_mod: callable=lambda c: c,\n",
    "                                         only_diag=False, n_jobs=1):\n",
    "    dist_srvs = get_all_srvs(num_of_qubits)  \n",
    "    cond_srvs = dist_srvs\n",
    "\n",
    "    values = torch.zeros((len(cond_srvs), len(dist_srvs)), device=device)\n",
    "\n",
    "    #---------------------\n",
    "\n",
    "    ent_bins, ent_labels = get_entanglement_bins(num_of_qubits)\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    for ent_bin in tqdm(ent_bins, total=len(ent_bins)):\n",
    "\n",
    "        true_samples = true_sample_bin_dist(samples_per_bin, len(ent_bin))\n",
    "        \n",
    "        for ind,srv in tqdm(enumerate(ent_bin), total=len(ent_bin)): \n",
    "            if exists(U): out_tensor = generate_comp_tensors(pipeline, prompt_mod(srv), U, true_samples[ind], system_size, num_of_qubits, max_gates, g=g, unique=False)\n",
    "            else:         out_tensor = generate_srv_tensors( pipeline, prompt_mod(srv),    true_samples[ind], system_size, num_of_qubits, max_gates, g=g, unique=False)\n",
    "\n",
    "            qc_list, error_cnt, svr_list = convert_tensors_to_srvs(out_tensor, gate_pool, n_jobs=n_jobs)\n",
    " \n",
    "            if only_diag:\n",
    "                values[i, i] = get_srv_accuracy(svr_list, srv)\n",
    "            else:\n",
    "                for j, dist_srv in enumerate(dist_srvs):      \n",
    "                    values[i, j] = get_srv_accuracy(svr_list, dist_srv)\n",
    "    \n",
    "            if not silent:\n",
    "                print(f\"{cond_srv}:      unique_cnt {out_tensor.unique(dim=0).shape[0]}      error_cnt {error_cnt}      acc {values[i, i]:.2f}\")\n",
    "\n",
    "            i += 1\n",
    "            \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd284fc6-c028-45c1-888d-b2bd8fa6a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def test_srv_clr_distribution(pipeline, samples_per_srv, system_size, num_of_qubits, max_gates, g, gate_pool, silent=False, device=\"cpu\", U=None, prompt_mod: callable=lambda c: c,\n",
    "                             dist_srvs=None, cond_srvs=None, only_diag=False, n_jobs=1):\n",
    "    if not exists(dist_srvs):\n",
    "        dist_srvs = get_all_srvs(num_of_qubits)  \n",
    "        \n",
    "    if not exists(cond_srvs):\n",
    "        cond_srvs = dist_srvs\n",
    "\n",
    "    values = torch.zeros((len(cond_srvs), len(dist_srvs)), device=device)\n",
    "\n",
    "    #---------------------\n",
    "      \n",
    "    for i, cond_srv in tqdm(enumerate(cond_srvs), total=len(cond_srvs)):    \n",
    "\n",
    "        if exists(U): out_tensor = generate_comp_tensors(pipeline, prompt_mod(cond_srv), U, samples_per_srv, system_size, num_of_qubits, max_gates, g=g, unique=False)\n",
    "        else:         out_tensor = generate_srv_tensors( pipeline, prompt_mod(cond_srv),    samples_per_srv, system_size, num_of_qubits, max_gates, g=g, unique=False)\n",
    "        \n",
    "        qc_list, error_cnt, svr_list = convert_tensors_to_srvs(out_tensor, gate_pool, n_jobs=n_jobs)\n",
    "                 \n",
    "        if only_diag:\n",
    "            values[i, i] = get_srv_accuracy(svr_list, srv)\n",
    "        else:\n",
    "            for j, dist_srv in enumerate(dist_srvs):      \n",
    "                values[i, j] = get_srv_accuracy(svr_list, dist_srv)\n",
    "\n",
    "        if not silent:\n",
    "            print(f\"{cond_srv}:      unique_cnt {out_tensor.unique(dim=0).shape[0]}      error_cnt {error_cnt}      acc {values[i, i]:.2f}\")\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d5177-b9a3-4852-8f6f-1bebc69efca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def test_guidance_dep(pipeline, srvs, samples, system_size, num_of_qubits, max_gates, gs, gate_pool, prompt_mod: callable=lambda c: c, U=None, n_jobs=1):        \n",
    "    guidance_dep_out = []\n",
    "\n",
    "    for srv in srvs:\n",
    "        unique_percentage_list      = []\n",
    "        error_cnt_percentage_list   = []\n",
    "        correct_srv_percentage_list = []\n",
    "        \n",
    "        for g in tqdm(gs):   \n",
    "            if exists(U): out_tensor = generate_comp_tensors(pipeline, prompt_mod(srv), U, samples, system_size, num_of_qubits, max_gates, g=g, unique=False)\n",
    "            else:         out_tensor = generate_srv_tensors( pipeline, prompt_mod(srv),    samples, system_size, num_of_qubits, max_gates, g=g, unique=False)\n",
    "                        \n",
    "            #---------------------------------\n",
    "            #calculate the copy percentage, dataset and sample? \n",
    "            \n",
    "            unique_percentage  = out_tensor.unique(dim=0).shape[0]/out_tensor.shape[0]             \n",
    "            unique_percentage_list.append(unique_percentage)\n",
    "                            \n",
    "            #---------------------------------\n",
    "            #decode tensors, get srv\n",
    "            \n",
    "            qc_list, error_cnt, svr_list = convert_tensors_to_srvs(out_tensor, gate_pool, n_jobs=n_jobs)\n",
    "            error_cnt_percentage_list.append(error_cnt/out_tensor.shape[0])\n",
    "            \n",
    "            #---------------------------------\n",
    "            #record the correct number       \n",
    "            \n",
    "            correct_srv_percentage = get_srv_accuracy(svr_list, srv)   \n",
    "            correct_srv_percentage_list.append(correct_srv_percentage)\n",
    "\n",
    "        guidance_dep_out.append((unique_percentage_list, error_cnt_percentage_list, correct_srv_percentage_list))\n",
    "    \n",
    "    return guidance_dep_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782437e-a1bb-45e0-835f-e02c173bc798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def test_srv_acc_vs_length(pipeline, samples, system_size, num_of_qubits, max_gates, g, gate_pool, prompt_mod: callable=lambda c: c, U=None, n_jobs=1):\n",
    "    ent_bins, ent_labels = get_entanglement_bins(num_of_qubits)\n",
    "    \n",
    "    ent_ls   = []\n",
    "    ent_accs = []\n",
    "    ent_cnts = []\n",
    "    \n",
    "    for ent_bin in tqdm(ent_bins, total=len(ent_bins)):\n",
    "        ls_acc = dict() #keep track over bins\n",
    "        ls_cnt = dict()\n",
    "\n",
    "        true_samples = true_sample_bin_dist(samples_per_bin, len(ent_bin))\n",
    "        \n",
    "        for ind,srv in enumerate(ent_bin): \n",
    "            if exists(U): out_tensor = generate_comp_tensors(pipeline, prompt_mod(srv), U, true_samples[ind], system_size, num_of_qubits, max_gates, g=g, unique=False)\n",
    "            else:         out_tensor = generate_srv_tensors( pipeline, prompt_mod(srv),    true_samples[ind], system_size, num_of_qubits, max_gates, g=g, unique=False)\n",
    "                                   \n",
    "            qc_list, error_cnt, svr_list = convert_tensors_to_srvs(out_tensor, gate_pool, n_jobs=n_jobs)     \n",
    "\n",
    "            lengths = get_circuit_gate_length(qc_list) #work in qc space to check only non errors\n",
    "\n",
    "            if lengths.numel() < 1: continue\n",
    "            \n",
    "            for l in lengths.unique(): #range(lengths.min(), lengths.max()):\n",
    "                indices = (lengths==l).nonzero().squeeze() \n",
    "                               \n",
    "                if indices.numel() > 0:                    \n",
    "                    srvs = torch.tensor(svr_list)[indices] \n",
    "                    if indices.dim() == 0: srvs = srvs.unsqueeze(0)\n",
    "                                            \n",
    "                    acc = get_srv_accuracy(srvs, srv)\n",
    "                    \n",
    "                    #----------    \n",
    "                    t = ls_acc.pop(l, [])\n",
    "                    t.append(acc)\n",
    "                    ls_acc[l] = t\n",
    "                    \n",
    "                    t = ls_cnt.pop(l, 0)\n",
    "                    t += srvs.shape[0]\n",
    "                    ls_cnt[l] = t\n",
    "                           \n",
    "        ls   = sorted(ls_acc)                   # sorted keys (l)\n",
    "        accs = [np.mean(ls_acc[l]) for l in ls] # average acc per l\n",
    "        cnts = [np.sum(ls_cnt[l]) for l in ls]\n",
    "        \n",
    "        ent_ls.append(ls)\n",
    "        ent_accs.append(accs)\n",
    "        ent_cnts.append(cnts)\n",
    "\n",
    "    return ent_ls, ent_accs, ent_cnts, ent_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48279f-ad30-474c-98e3-da6d2d94f32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def test_srv_acc_vs_maxLength(pipeline, samples_per_bin, system_size, num_of_qubits, max_gates_list, g, gate_pool, prompt_mod: callable=lambda c: c, U=None, n_jobs=1):\n",
    "    ent_bins, ent_labels = get_entanglement_bins(num_of_qubits)\n",
    "    \n",
    "    ent_accs = []\n",
    "    for ent_bin in tqdm(ent_bins, total=len(ent_bins)):\n",
    "        \n",
    "        true_samples = true_sample_bin_dist(samples_per_bin, len(ent_bin))\n",
    "        \n",
    "        bin_accs = []\n",
    "        for max_gates in max_gates_list:\n",
    "\n",
    "            accs = []\n",
    "            for ind,srv in enumerate(ent_bin): \n",
    "                if exists(U): out_tensor = generate_comp_tensors(pipeline, prompt_mod(srv), U, true_samples[ind], system_size, num_of_qubits, max_gates, g=g, unique=False)\n",
    "                else:         out_tensor = generate_srv_tensors( pipeline, prompt_mod(srv),    true_samples[ind], system_size, num_of_qubits, max_gates, g=g, unique=False)\n",
    "                                   \n",
    "                qc_list, error_cnt, svr_list = convert_tensors_to_srvs(out_tensor, gate_pool, n_jobs=n_jobs)     \n",
    "\n",
    "                acc = get_srv_accuracy(svr_list, srv)\n",
    "                \n",
    "                accs.append(acc)       \n",
    "            bin_accs.append(np.mean(accs))     \n",
    "        ent_accs.append(bin_accs)\n",
    "        \n",
    "    return ent_accs, ent_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc9c5c-41c6-4905-8d2e-76e301cef284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def test_srv_length_distribution(pipeline, samples_per_bin, system_size, num_of_qubits, max_gates, g, gate_pool, silent=False, U=None, prompt_mod: callable=lambda c: c, n_jobs=1):\n",
    "    ent_bins, ent_labels = get_entanglement_bins(num_of_qubits)\n",
    "\n",
    "    ls = []\n",
    "    \n",
    "    for ent_bin in tqdm(ent_bins, total=len(ent_bins)):\n",
    "\n",
    "        true_samples = true_sample_bin_dist(samples_per_bin, len(ent_bin))\n",
    "        \n",
    "        bin_ls = []\n",
    "        \n",
    "        for ind,srv in tqdm(enumerate(ent_bin), total=len(ent_bin)): \n",
    "            if exists(U): out_tensor = generate_comp_tensors(pipeline, prompt_mod(srv), U, true_samples[ind], system_size, num_of_qubits, max_gates, g=g, unique=False)\n",
    "            else:         out_tensor = generate_srv_tensors( pipeline, prompt_mod(srv),    true_samples[ind], system_size, num_of_qubits, max_gates, g=g, unique=False)\n",
    "\n",
    "            qc_list, error_cnt, svr_list = convert_tensors_to_srvs(out_tensor, gate_pool, n_jobs=n_jobs)\n",
    "\n",
    "            qc_ls = get_circuit_gate_length(qc_list) #tensor [qcs]\n",
    "            bin_ls.append(qc_ls)\n",
    "\n",
    "        ls.append(torch.cat(bin_ls))\n",
    "\n",
    "    return ls #[ent_bins, num_of_non_err_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717dcd10-5e19-4bf7-a8ac-7e360c9e9e08",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9df84e-d680-4db0-907d-913fe68fe782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_srv_clr_distribution_hist(values, samples, num_of_qubits, save=False, dist_srvs=None, cond_srvs=None):\n",
    "    if not exists(dist_srvs):\n",
    "        dist_srvs = get_all_srvs(num_of_qubits)  \n",
    "        \n",
    "    if not exists(cond_srvs):\n",
    "        cond_srvs = dist_srvs\n",
    "\n",
    "    n         = len(dist_srvs)\n",
    "    values    = values.cpu()\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,12))#, constrained_layout=True) \n",
    "    plt.title(f\"Generated samples per condition: {samples}\")\n",
    "    plt.ylabel(r\"Condition\")\n",
    "    plt.xlabel(r\"Generated distribution\")\n",
    "\n",
    "    #--------------------------------------------\n",
    "    if num_of_qubits < 6 or 0:\n",
    "        plt.yticks(range(len(cond_srvs)), [str(b) for b in cond_srvs])\n",
    "        plt.xticks(range(n), [str(b) for b in dist_srvs], rotation=90 if n>3 else 0)\n",
    "    else:\n",
    "        plt.yticks([])\n",
    "        plt.xticks([])\n",
    "\n",
    "    #--------------------------------------------\n",
    "    plt.imshow(values, vmin=0, vmax=1)\n",
    "    # plt.imshow(values.cpu(), norm=\"log\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    #--------------------------------------------\n",
    "    #print acc\n",
    "    x_shift = 1*40 if num_of_qubits==5 else 0\n",
    "    if num_of_qubits < 4:\n",
    "        for i in range(n): \n",
    "            plt.text(x_shift+i, i, f\"{values[i, i]:0.2f}\", color='black', ha='center', va='center', fontsize=\"large\")\n",
    "\n",
    "    #--------------------------------------------\n",
    "    #draw rects\n",
    "    off = 0.5\n",
    "    for i in range(2, num_of_qubits):\n",
    "        w = scipy.special.comb(num_of_qubits, i, exact=True)\n",
    "        plt.gca().add_patch(plt.Rectangle((off, off), w, w, ls=\"-\", ec=\"white\", fc=\"none\")) #, transform=plt.gca().transAxes))\n",
    "        off += w\n",
    "\n",
    "    #--------------------------------------------\n",
    "    #print average acc for rects\n",
    "    off = 0\n",
    "    for i in [0]+list(range(2, num_of_qubits+1)):\n",
    "        w = scipy.special.comb(num_of_qubits, i, exact=True)   \n",
    "        d1 = off\n",
    "        d2 = d1 + w\n",
    "        mean_acc = values[d1:d2, d1:d2].diag().mean()\n",
    "        plt.text(off+2*w/3, off+w/7, f\"{mean_acc:0.2f}\", color='red', ha='center', va='center', fontsize=\"x-large\")   \n",
    "        off += w\n",
    "\n",
    "    #--------------------------------------------\n",
    "    if save:\n",
    "        plt.savefig('plot_srv_clr_distribution_hist.svg', bbox_inches='tight')\n",
    "      \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18161ea0-df08-4ba1-8e45-5a5d58bdd73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_srv_clr_distribution_bin_accuracy(values, samples, num_of_qubits, save=False, plot_percentages=False, trainSet_srv=None):\n",
    "    values = values.cpu().diag()\n",
    "    ent_bins, ent_labels = get_entanglement_bins(num_of_qubits)\n",
    "    \n",
    "    n = sum(len(srvs) for srvs in ent_bins)\n",
    "    x = np.arange(n)  # the label locations\n",
    "    width = 0.8\n",
    "\n",
    "    #------------------------\n",
    "    fig = plt.figure(figsize=(6.6, 4), constrained_layout=True) \n",
    "    # plt.title(f\"Generated samples per condition: {samples}\", fontsize=14)\n",
    "    plt.ylabel(r\"Accuracy\", fontsize=25)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.xticks([])\n",
    " \n",
    "    i = 0\n",
    "    for j,(label, srvs) in enumerate(zip(ent_labels, ent_bins)):   \n",
    "        label = f\"{sum(srvs[0])-num_of_qubits}\"\n",
    "        incre = len(srvs)\n",
    "        rects = plt.bar(x[i:i+incre], values[i:i+incre], width, label=label)\n",
    "        i += incre\n",
    "        if plot_percentages: plt.gca().bar_label(rects, padding=3, fmt=\"%0.2f\")\n",
    "\n",
    "    ncols = len(ent_labels)//2+1 if len(ent_labels) > 5 else len(ent_labels)\n",
    "    leg1 = plt.legend(loc=\"lower center\", fontsize=14, ncols=ncols, title=\"# of entangled qubits:\", title_fontsize=14,bbox_to_anchor=(0.5, 1.01))\n",
    "    ax = fig.add_artist(leg1)\n",
    "    \n",
    "    if exists(trainSet_srv):\n",
    "        if trainSet_srv.shape[-1]==num_of_qubits:\n",
    "            srvs = []\n",
    "            for s in ent_bins: srvs.extend(s)\n",
    "            \n",
    "            dataset_percentages = [get_srv_accuracy(trainSet_srv, srv).cpu() for srv in srvs]\n",
    "            xmin = x - width*0.55\n",
    "            xmax = x + width*0.55            \n",
    "            ag = plt.hlines(dataset_percentages, xmin, xmax, label=\"Random sampling\" , color=\"black\", linestyle=\"-\", linewidths=2.3)\n",
    "        \n",
    "            plt.legend(handles=[ag], fontsize=14, frameon=False)\n",
    "\n",
    "    ymin, ymax = plt.ylim()    \n",
    "    plt.ylim(ymin, ymax+0.04)\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(f\"plot_srv_clr_distribution_bin_accuracy.svg\", bbox_inches='tight', transparent=True)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feddf06-e127-4cca-bf8e-0c2cc173c839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_guidance_dep(srvs, gs, guidance_dep_out, samples, save=False):    \n",
    "    assert len(srvs) == len(guidance_dep_out)\n",
    "\n",
    "    n = len(srvs)\n",
    "    fig, axs = plt.subplots(1, n, figsize=(12, 5), squeeze=False, constrained_layout=True)   \n",
    "    fig.suptitle(fr\"Generated {samples} samples per $g$ and SRV\")\n",
    "    \n",
    "    for i,srv in enumerate(srvs):  \n",
    "        unique_percentage_list, error_cnt_percentage_list, correct_srv_percentage_list = guidance_dep_out[i]\n",
    "                     \n",
    "        #---------------------------------\n",
    "        #plot now gs vs the numbers   \n",
    "            \n",
    "        plt.sca(axs[0, i])\n",
    "        plt.xlabel(r\"Guidance scale $g$\")     \n",
    "        plt.title(f\"SRV = {srv}\")\n",
    "        plt.plot(gs, unique_percentage_list     , label=\"Unique tensors percentage\")\n",
    "        plt.plot(gs, error_cnt_percentage_list  , label=\"Error circuits percentage\")\n",
    "        plt.plot(gs, correct_srv_percentage_list, label=\"Correct SRV percentage\")\n",
    "        \n",
    "        if i == (n-1): plt.legend() \n",
    "\n",
    "    if save:\n",
    "        plt.savefig(\"plot_guidance_dep.svg\", bbox_inches='tight', transparent=True)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cdecfb-080b-49c3-a13e-d9a7c1711fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_srv_acc_vs_length(ent_ls, ent_accs, ent_cnts, ent_labels, samples, plot_dist=True, save=False):\n",
    "    fig, axs = plt.subplots(2 if plot_dist else 1, 1, figsize=(12, 7), squeeze=False, constrained_layout=True) \n",
    "\n",
    "    #-------------------\n",
    "    plt.sca(axs[0,0])\n",
    "    plt.title(f\"Generated samples per entanglement: {samples}\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Gate number\")\n",
    "    for i,ent_label in enumerate(ent_labels): \n",
    "        plt.plot(ent_ls[i], ent_accs[i], label=f\"{ent_label}\")\n",
    "    plt.legend()\n",
    "\n",
    "    #-------------------\n",
    "    if plot_dist:\n",
    "        plt.sca(axs[1,0])\n",
    "        plt.title(f\"Used samples per l to calculate accuracy, should match gate distribution\")\n",
    "        plt.ylabel(\"Used samples\")\n",
    "        plt.xlabel(\"Gate number\")\n",
    "        for i,ent_label in enumerate(ent_labels): \n",
    "            plt.plot(ent_ls[i], ent_cnts[i], label=f\"{ent_label}\")\n",
    "        plt.legend()\n",
    "\n",
    "    #-------------------\n",
    "    if save:\n",
    "        plt.savefig('plot_srv_acc_vs_length.svg', bbox_inches='tight')\n",
    "         \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c4ebca-e67c-4d8e-bea1-7e0e2cce5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_srv_acc_vs_maxLength(ent_accs, ent_labels, max_gates_list, samples, plot_dist=True, save=False):\n",
    "    fig = plt.figure(figsize=(12, 4), constrained_layout=True) \n",
    "    \n",
    "    plt.title(f\"Generated samples per maxGates per entanglement: {samples}\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Max number of gates / tensor size\")\n",
    "    plt.xticks(max_gates_list)\n",
    "    \n",
    "    for ent_acc,ent_label in zip(ent_accs, ent_labels): \n",
    "        plt.plot(max_gates_list, ent_acc, label=f\"{ent_label}\")\n",
    "        \n",
    "    plt.legend()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig('plot_srv_acc_vs_length.svg', bbox_inches='tight')\n",
    "         \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f26a8-ac40-4e91-8c0e-1ef07a0fd4f4",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0474216-8e0c-4ba7-9a37-571ac7d8e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
